<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">
<meta property="og:type" content="website">
<meta property="og:title" content="牧牧闻叨">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="牧牧闻叨">
<meta property="og:description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="牧牧闻叨">
<meta name="twitter:description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> 牧牧闻叨 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">牧牧闻叨</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">整理心中的知识体系，让自己变得更好</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/25/Kernel-SVM/" itemprop="url">
                  Kernel SVM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-25T18:49:51+08:00" content="2017-07-25">
              2017-07-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageKernel_SVM.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part3-4"><a href="#Machine-Learning-A-Z-Part3-4" class="headerlink" title="Machine Learning A-Z Part3 - 4"></a>Machine Learning A-Z Part3 - 4</h1><h2 id="Kernel-SVM"><a href="#Kernel-SVM" class="headerlink" title="Kernel SVM"></a>Kernel SVM</h2><h3 id="Kernel-SVM-Intuition"><a href="#Kernel-SVM-Intuition" class="headerlink" title="Kernel SVM Intuition"></a>Kernel SVM Intuition</h3><h4 id="The-Problem-we-met"><a href="#The-Problem-we-met" class="headerlink" title="The Problem we met"></a>The Problem we met</h4><p>之前我们看到的数据集都是分布的很好的，可以用线性边缘将两个分类变量数据组分割开来的，但是如果我们遇到的数据并不是这样分布的，而是呈现边缘非线性分布的，那我们该怎么样才能有效的分隔开两个不同的分类数据呢？</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM1.png" alt="how to classify"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM2.png" alt="linear vs non-linear"></p>
<h4 id="方法1-Mapping-to-higher-Dimension"><a href="#方法1-Mapping-to-higher-Dimension" class="headerlink" title="方法1 - Mapping to higher Dimension"></a>方法1 - Mapping to higher Dimension</h4><p>这种方法的核心思想就是<strong>通过对原有数据实行函数运算转换，让原有的数据映射到新的更高维度的空间中，让转换后的数据在新的空间维度中呈现分离的，可以用线性边缘切分开的分布，再映射回原来的维度，以此达到分类的目的。</strong></p>
<p>下面我们来看一下图示：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM3.png" alt="mapping to higher Dimension"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM4.png" alt="2D to 3D"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM5.png" alt="3D to 2D"></p>
<p>虽然这个想法让我们眼前一亮，感觉这样的做法好像的确可行。但是这种方法其实是有潜在问题的。<strong>且不说我们是否每次都能找到合适的函数让数据在高阶的维度中呈现分离的分布状态，更重要的是，即使找到了我们也会面临巨大的计算量，我们不仅仅要将庞大的数据集中的所有数据都进行转换运算，分类完成后我们还要将那些数据反转换，又映射回原先的维度。</strong></p>
<h4 id="方法2-the-Kernel-Trick"><a href="#方法2-the-Kernel-Trick" class="headerlink" title="方法2 - the Kernel Trick"></a>方法2 - the Kernel Trick</h4><p>为了不必再整个数据集上提高数据的维度，减少不必要的计算量，人们找到了另外一种算法，就是<code>kernel trick</code>。这种方法是利用特殊函数（这里用<code>RBF</code>来作为例子）来对数据进行分类，主要看数据进行运算后的值是大于0还是等于0（因为指数函数不会小于0）。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM6.png" alt="RBF"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM7.png" alt="classify boundary"></p>
<p>因为这个函数是中心凸起的，有明显的边界——即图像中看起来像小山丘一样的东西的底部。所以我们先选定一个分类中心点(<code>landmark</code>)，然后通过调整函数的$\delta$来改变函数的边界。<strong>当$\delta$变大时，边界就放宽，当$\delta$变小是，边界就收窄。</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM8.png" alt="wider boundary"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM9.png" alt="lower delta"></p>
<p>这个函数并非只能单个使用，我们还可以把好几个函数加在一起，选择不同的$\delta$和<code>landmark</code>一起组合形成更为复杂的边界。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM10.png" alt="more complex boundary"></p>
<h4 id="More-kernel-function"><a href="#More-kernel-function" class="headerlink" title="More kernel function"></a>More kernel function</h4><p>除了<code>RBF</code>之外还有别的函数可以得到非线性的函数边界</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM11.png" alt="more function"></p>
<p>如果希望更直观的查看不同<code>kernel funciton</code>的三维图像，那可以访问<a href="mlkernels.readthedocs.io/en/latest/kernelfunctions.html">这个网站</a>。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="fit-the-model"><a href="#fit-the-model" class="headerlink" title="fit the model"></a>fit the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">classifier = SVC(kernel=<span class="string">'rbf'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p>可以看到这里和之前的代码唯一的不同就是设置了<code>kernel=&#39;rbf&#39;</code>，即让模型使用<code>RBF</code>算法得到非线性的分类边界。</p>
<h4 id="see-the-result"><a href="#see-the-result" class="headerlink" title="see the result"></a>see the result</h4><h5 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h5><p>建模完毕后我们看到该模型的混淆矩阵，模型的表现也是非常的好，只预测错了7个。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM_cm.png" alt="cm"></p>
<h5 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h5><p>再来看下模型的可视化结果，这下我们可以明显感受到设置参数<code>kernel=&#39;linear&#39;</code>和设置参数<code>kernel=&#39;rbf&#39;</code>的区别了。<code>RBF</code>得到的模型边缘是曲线的，更精细化的分割开了两个类别。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM_plot_train.png" alt="plot_train"></p>
<p>以下是测试集的图形：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Kernel_SVM_plot_test.png" alt="plot_test"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/24/日常饮食和爱/" itemprop="url">
                  日常饮食和爱
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-24T19:38:14+08:00" content="2017-07-24">
              2017-07-24
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/牧牧/" itemprop="url" rel="index">
                    <span itemprop="name">牧牧</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimage%E6%97%A5%E5%B8%B8%E7%94%9F%E6%B4%BB%E4%B8%8E%E7%88%B1.jpg" class="full-image"></p>
<p style="text-align: center;text-height: 34px;font-size: 20px"><br>    我喜欢这样的日子<br>    三两个小菜<br>    两个碗<br>    两双筷<br>    两盏杯<br>    两人对坐<br></p>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/24/SVM/" itemprop="url">
                  SVM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-24T19:11:19+08:00" content="2017-07-24">
              2017-07-24
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageSVM.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part3-3"><a href="#Machine-Learning-A-Z-Part3-3" class="headerlink" title="Machine Learning A-Z Part3 - 3"></a>Machine Learning A-Z Part3 - 3</h1><h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><h3 id="SVM-Intuition"><a href="#SVM-Intuition" class="headerlink" title="SVM Intuition"></a>SVM Intuition</h3><p>Support Vector Machine(SVM)是很火的机器学习算法。先来看下这种模型是解决什么样的问题的。<strong>简单来说这种模型就是要找到划分分类数据的最佳边界，这样之后要预测的特征值落到哪边，就划分为对应的分类变量。</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/SVM_1.png" alt="SVM1"></p>
<p>最主要的原理就是找到两组分类变量中距离最近的数据，然后根据最大边界值(max margin)来求得最合适的划分边界。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/SVM_3.png" alt="SVM3"></p>
<p>SVM模型中一些其他的词汇：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/SVM_2.png" alt="SVM2"></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="fitting-the-model"><a href="#fitting-the-model" class="headerlink" title="fitting the model"></a>fitting the model</h4><p>老式三步走：</p>
<ol>
<li>从<code>sklearn.svm</code>中导入<code>SVC</code>对象</li>
<li>建立<code>SVC</code>实例</li>
<li><code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting svm to the Training set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">classifier = SVC(kernel=<span class="string">'linear'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/SVM_fit.png" alt="fit"></p>
<blockquote>
<p>参数<code>kernel=</code>是选择SVM的模型算法，这次我们选择的是最简单的线性<code>linear</code>。他还有很多别的算法——<code>‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’</code>。这个参数可以说是最重要的参数，因为它会决定模型分类边界是线性的还是非线性的。</p>
</blockquote>
<h4 id="see-the-results"><a href="#see-the-results" class="headerlink" title="see the results"></a>see the results</h4><h5 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h5><p>得到混淆矩阵的代码和之前一样，就不再重复了，这里我们仅仅看得到的混淆矩阵。共预测错误10个，也可以说是很好的模型了。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/SVM_cm.png" alt="CM"></p>
<h5 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h5><p>绘图的代码也不再重复，我们直接可以看绘制的模型图形。这个图形有些眼熟，它和我们之前看过的逻辑回归的图形很像，这是因为我们在参数中设置<code>kernel=&#39;linear&#39;</code>，所以我们得到的模型的边界是线性的。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/svm_plot.png" alt="plot_train"></p>
<p>下面是预测集绘制的图。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/svm_plot_test.png" alt="plot_test"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/24/K-NN/" itemprop="url">
                  K-NN
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-24T12:42:27+08:00" content="2017-07-24">
              2017-07-24
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageKNN.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part3-2"><a href="#Machine-Learning-A-Z-Part3-2" class="headerlink" title="Machine Learning A-Z Part3 - 2"></a>Machine Learning A-Z Part3 - 2</h1><h2 id="K-NN"><a href="#K-NN" class="headerlink" title="K-NN"></a>K-NN</h2><h3 id="K-Nearest-Neighbor-Intuition"><a href="#K-Nearest-Neighbor-Intuition" class="headerlink" title="K-Nearest Neighbor Intuition"></a>K-Nearest Neighbor Intuition</h3><p>我们首先要明确我们使用KNN模型的时候是为了解决一些什么样的问题：如果给出差异很大的数据，比如都是个位数的数据和都是三位数的数据，稍微取个平均值什么的，机器就可以区分出来他们的分组。<strong>但是问题是如果给出一个新的中间值数据，我们该如何确认其属于哪个分组呢？</strong>这就是KNN要解决的问题，并应用于预测分类数据。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN1.png" alt="KNN1"></p>
<p>KNN模型有四个步骤：</p>
<ol>
<li>先选择我们要选取的临近样本点的个数<em>k</em></li>
<li>计算我们要分类的点和其他各个点的<em>欧氏距离</em>，并选取最近的<em>k</em>个数据点</li>
<li>查看在这<em>k</em>个点中属于<em>1类</em>的有几个，属于<em>2类</em>的有几个</li>
<li>这<em>k</em>个数据中属于哪边的点多，最终就把我们要预测的点划分为哪边</li>
</ol>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN2.png" alt="KNN2"></p>
<p><strong>下面用更形象的图画来示意KNN模型是如何执行分类预测的</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN3.png" alt="KNN3"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN4.png" alt="KNN4"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN5.png" alt="KNN5"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN6.png" alt="KNN6"></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p>由于还是使用一样的数据集进行分类变量的预测，所以数据预处理我们就不再重复了，直接讲讲不一样的东西。</p>
<h4 id="fit-the-model"><a href="#fit-the-model" class="headerlink" title="fit the model"></a>fit the model</h4><p>老式三步走：</p>
<ol>
<li>从<code>sklearn.neighbors</code>中导入<code>KNeighborsClassifier</code>对象</li>
<li>建立<code>KNeighborsClassifier（）</code>实例</li>
<li><code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">classifier = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,</span><br><span class="line">                                  metric=<span class="string">'minkowski'</span>,</span><br><span class="line">                                  p=<span class="number">2</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN_fit.png" alt="fit"></p>
<blockquote>
<p>参数<code>n_neighbors=5</code>就是我们所说的要选取的k个数据点。而参数<code>metric=&#39;minkowski&#39;, p=2</code>组合起来就是指定模型用<em>欧氏距离</em>做为距离运算的算法。</p>
</blockquote>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN_doc.png" alt="doc"></p>
<h4 id="test-the-result"><a href="#test-the-result" class="headerlink" title="test the result"></a>test the result</h4><h5 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h5><p>和之前一样，我们可以通过混淆矩阵来观测模型的好坏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"><span class="comment"># Making the Confusion Matrix</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN_cm.png" alt="cm"></p>
<p>从矩阵中我们可以看到KNN模型的表现非常好，总共只预测错了7个数据。</p>
<h5 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Training set results</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">X_set, y_set = X_train, y_train</span><br><span class="line">X1, X2 = np.meshgrid(np.arange(start = X_set[:, <span class="number">0</span>].min() - <span class="number">1</span>, stop = X_set[:, <span class="number">0</span>].max() + <span class="number">1</span>, step = <span class="number">0.01</span>),</span><br><span class="line">                     np.arange(start = X_set[:, <span class="number">1</span>].min() - <span class="number">1</span>, stop = X_set[:, <span class="number">1</span>].max() + <span class="number">1</span>, step = <span class="number">0.01</span>))</span><br><span class="line">plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),</span><br><span class="line">             alpha = <span class="number">0.75</span>, cmap = ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>)))</span><br><span class="line">plt.xlim(X1.min(), X1.max())</span><br><span class="line">plt.ylim(X2.min(), X2.max())</span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> enumerate(np.unique(y_set)):</span><br><span class="line">    plt.scatter(X_set[y_set == j, <span class="number">0</span>], X_set[y_set == j, <span class="number">1</span>],</span><br><span class="line">                c = ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>))(i), label = j)</span><br><span class="line">plt.title(<span class="string">'K-NN (Training set)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Age'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Estimated Salary'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>可以看到图像中KNN模型的边缘是很复杂的，不仅仅是线性或者非线性的弧形那么简单，在斯坦福的<em>Statistical Learning</em>课程中老师也提到，<strong>当我们能看出数据分布的边缘是极度复杂的，连普通的非线性模型也无法很好拟合的时候，我们再考虑使用KNN模型。</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN_plot_train.png" alt="train_plot"></p>
<p>下面是测试集的图形：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/K_NN_plot_test.png" alt="test_plot"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Logistic-Regression/" itemprop="url">
                  Logistic Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:34:13+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageLogistic_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part3-1"><a href="#Machine-Learning-A-Z-Part3-1" class="headerlink" title="Machine Learning A-Z Part3 - 1"></a>Machine Learning A-Z Part3 - 1</h1><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><h3 id="Logistic-Regression-Intuition"><a href="#Logistic-Regression-Intuition" class="headerlink" title="Logistic Regression Intuition"></a>Logistic Regression Intuition</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression1.png" alt="problem with linear regressor"><br><strong>有时候我们要预测的值并不是连续变量，可能是分类变量，比如一个顾客是会 买 还是 不买 某个商品。</strong>这种情况下我们使用线性回归就不太合适，不能很好的对情况进行预测，因为线性回归产生的预测值也是连续值，最大的问题就是，<strong>线性回归模型会产生超过1和小于0的预测值</strong>，这些预测值无法作为概率来理解，这让线性回归模型不适合预测分类变量这种情景。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression2.png" alt="Logistic1"></p>
<p>为了让特征值能使用连续变量，而预测值却限定在 0-1 之间，逻辑回归就出现了。逻辑回归也是预测连续变量，但是他的特点是能把预测值限定在0-1之间。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression3.png" alt="Logistic2"></p>
<p>这种模型预测的是分类变量的概率，<strong>通常还要有一个决策标准，即判定概率多上以上就判定为1，其余的判定为另一种分类变量</strong>。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h4><p>这次处理的数据大致结构如下：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_dataset.png" alt="dataset"></p>
<p>由于逻辑回归是使用连续变量来预测分类变量的，所以我们只需要选取元数据中的连续变量作为特征值即可。</p>
<p>在切割完数据之后，我们还需要对数据进行<em>Feature Scaling</em>处理，因为我们希望模型不要受到不同度量衡的影响，处理过的数据让数据更加准确。这里只需要对特征值进行标准化处理就可以了，预测值因为已经是分类变量，所以是不需要进行<em>Feature Scaling</em>的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Social_Network_Ads.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, <span class="number">2</span>:<span class="number">4</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">4</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.25</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="Fit-the-model"><a href="#Fit-the-model" class="headerlink" title="Fit the model"></a>Fit the model</h4><p>还是往常一样的三步走：</p>
<ol>
<li>从<code>sklearn.linear_model</code> import <code>LogisticRegression</code></li>
<li>建立一个<code>LogisticRegression</code>实例</li>
<li>将该对象实例<code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">classifier = LogisticRegression(random_state = <span class="number">0</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression4.png" alt="fit Logistic"></p>
<h4 id="Predict"><a href="#Predict" class="headerlink" title="Predict"></a>Predict</h4><p>利用模型进行预测也没有什么好多说的，没有什么不同，还是用模型的<code>predict()</code>方法即可，但是要注意<strong>我们在预处理的时候就把测试集的特征值先进行了标准化，如果我们预测的不是测试集，那么也需要先对数据进行标准化处理。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = classifier.predict(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="Making-the-confusion-matrix"><a href="#Making-the-confusion-matrix" class="headerlink" title="Making the confusion matrix"></a>Making the confusion matrix</h4><p>混淆矩阵是很清晰的展示分类模型的好坏的一个工具，它的原理就是建立一个矩阵，将数据真实的分类值和预测的分类值进行比较，有<code>(1, 1)</code> - 实际为真，预测为真; <code>(1, 0)</code> - 实际为真，预测为假 <strong>I类错误</strong>; <code>(0, 1)</code> - 实际为假，预测为真 <strong>II类错误</strong>; <code>(0, 0)</code> - 实际为假，预测为假 四种。</p>
<p>在python中，我们使用<code>sklearn.metrics</code>中的<code>confusion_matrix</code>对象来创建混淆矩阵。需要输入的系数有：<code>y_true=</code>代表真正值的数据集(array)；<code>y_pred=</code>预测值的集合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm = confusion_matrix(y_true=y_test, y_pred=y_pred)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/cm.png" alt="confusion_matrix"></p>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>这次的可视化比较复杂，但也因为特征值是二维数据，所以和之前的一维数据相比，绘制的图形也更为直观，更为有趣。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import color map class</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="comment"># copy X_test and y_test array, simplify reuse process</span></span><br><span class="line">X_set, y_set = X_test, y_test</span><br><span class="line"><span class="comment"># Create array used for total panel and axis</span></span><br><span class="line"><span class="comment"># make range a little wider than data range of dataset</span></span><br><span class="line"><span class="comment"># avoid data fall into edge of plot, make plot looks clear</span></span><br><span class="line">X1, X2 = np.meshgrid(np.arange(start=X_set[:, <span class="number">0</span>].min() <span class="number">-1</span>, stop=X_set[:, <span class="number">0</span>].max() + <span class="number">1</span>, step=<span class="number">0.01</span>),</span><br><span class="line">                     np.arange(start=X_set[:, <span class="number">1</span>].min() <span class="number">-1</span>, stop=X_set[:, <span class="number">1</span>].max() + <span class="number">1</span>, step=<span class="number">0.01</span>))</span><br><span class="line"><span class="comment"># draw a panel pixel by pixel</span></span><br><span class="line">plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),</span><br><span class="line">             alpha=<span class="number">0.75</span>, cmap=ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>)))</span><br><span class="line"><span class="comment"># limit plot's axis</span></span><br><span class="line">plt.xlim(X1.min(), X1.max())</span><br><span class="line">plt.ylim(X2.min(), X2.max())</span><br><span class="line"><span class="comment"># making scatter plot</span></span><br><span class="line"><span class="comment"># use y as index to loop all data and fill in different colors</span></span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> enumerate(np.unique(y_set)):</span><br><span class="line">    plt.scatter(X_set[y_set == j, <span class="number">0</span>], X_set[y_set == j, <span class="number">1</span>],</span><br><span class="line">                c = ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>))(i), label = j)</span><br><span class="line"><span class="comment"># make some additional decoration</span></span><br><span class="line">plt.title(<span class="string">'Logistic Regression (Test Set)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Age'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Estimated Salary'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_plot_test.png" alt="plot test"></p>
<p>同样的方法也可以绘制训练集的图</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_plot_train.png" alt="plot train"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Evaluating-Regression-Models-Performance/" itemprop="url">
                  Evaluating Regression Models Performance
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:27:38+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageEvaluating_Regressor.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-7"><a href="#Machine-Learning-A-Z-Part2-7" class="headerlink" title="Machine Learning A-Z Part2 - 7"></a>Machine Learning A-Z Part2 - 7</h1><h2 id="Evaluating-Regression-Models-Performance"><a href="#Evaluating-Regression-Models-Performance" class="headerlink" title="Evaluating Regression Models Performance"></a>Evaluating Regression Models Performance</h2><h3 id="两个判断模型好坏的指标"><a href="#两个判断模型好坏的指标" class="headerlink" title="两个判断模型好坏的指标"></a>两个判断模型好坏的指标</h3><h3 id="R-Square"><a href="#R-Square" class="headerlink" title="R Square"></a>R Square</h3><p><strong>R方</strong>是我们比较熟悉的一个统计指标了，它的大小显示了一个模型的优劣程度。他的公式是</p>
<p>$SS<em>{res} = \sum(y</em>{i} - \hat y_{i})$</p>
<p>$SS<em>{tot} = \sum(y</em>{i} - \hat y_{avg})$</p>
<p>$R^{2} = 1 - \frac{SS<em>{res}}{SS</em>{tot}}$</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/R_squared1.png" alt="R Square"></p>
<p>用平均值来作为预测值是每个人都可以想得到的，没有什么技术含量，作为比较的基准。我们建立的模型的残差作为比较值，放入$R^{2}$中进行计算，模型效果越好，残差越小，$R^{2}$越大；相反的，模型越差，残差越大，$R^{2}$越小。</p>
<p><strong>所以，模型越好，$R^{2}$越大，模型越差，$R^{2}$越小。</strong></p>
<h3 id="Adjusted-R-Square"><a href="#Adjusted-R-Square" class="headerlink" title="Adjusted R Square"></a>Adjusted R Square</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com/Adj_R_squared1.png" alt="Problem with R Square"><br>但是R方有一个致命的缺点——随着变量个数的增加，R方只会上升，不会下降。之前学习R语言的时候老师也提到过，之前在建立模型只看R方判断的前提下，很多高校的教授为了超高的R方，就在模型中加入各种变量，把模型公式弄得很长很复杂，但是其中加入的变量有些根本和预测值没有什么关系，仅仅是放进来增加R方用的。</p>
<p>$$Adj \ R^{2} = 1 - (1 - R^{2})\frac{n - 1}{n -p - 1}$$</p>
<blockquote>
<p><strong>n</strong> is the sample size<br><strong>p</strong> is the total number of explanatory variables in the model (not including the constant term)</p>
</blockquote>
<p>为了避免这种情况，人们发明了<strong>调整R方</strong>，从本质上来说，它和R方最大的不同就是<strong>调整R方中加入了惩罚系数——即$\frac{n - 1}{n -p - 1}$</strong>。当加入的变量相关性并不是那么显著的时候，惩罚系数的削减效用会占主要作用，此时调整R方会减小。因此也就避免了盲目加入过多变量的现象，给了人们更直观的判断依据。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Adj_R_squared2.png" alt="Adj R Square"></p>
<h3 id="不要掉入相关系数的陷阱"><a href="#不要掉入相关系数的陷阱" class="headerlink" title="不要掉入相关系数的陷阱"></a>不要掉入相关系数的陷阱</h3><p>有的人认为一个变量的重要与否主要要看他的相关系数是否很大，大的话就很有用，就很好。其实不是这样的，因为相关系数的大小只是单位变动的体现。<strong>也就是说，相关系数和单位有很大的关系，当度量衡变小的时候，相关系数就相应的放大，度量衡变大的时候，先关系数就相应的缩小。</strong></p>
<p>举例来说，我们观察气温和商场营业额的模型，如果商场营业额用万元来算，那么相关系数就会很小，可能每摄氏度的变化给营业额造成的影响才1或者0.1，但是<strong>那可是1万元啊！</strong>相对的，如果用元来衡量的话，那相关系数就会变成10000，看起来很大吧？可是表达的意思却没什么不同，还是一个意思。<strong>一个是1万元，一个是10000元。</strong></p>
<h3 id="回归模型各有什么优劣？"><a href="#回归模型各有什么优劣？" class="headerlink" title="回归模型各有什么优劣？"></a>回归模型各有什么优劣？</h3><p>下面这张图可以总结性的概括过去学习的回归模型的优势和劣势：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Regression-Pros-Cons.jpg" alt="pros-cons"></p>
<h3 id="如何选择该使用哪个模型？"><a href="#如何选择该使用哪个模型？" class="headerlink" title="如何选择该使用哪个模型？"></a>如何选择该使用哪个模型？</h3><blockquote>
<p>First, you need to figure out whether your problem is linear or non linear. You will learn how to do that in Part 10 - Model Selection. Then:</p>
<p>If your problem is linear, you should go for Simple Linear Regression if you only have one feature, and Multiple Linear Regression if you have several features.</p>
<p>If your problem is non linear, you should go for Polynomial Regression, SVR, Decision Tree or Random Forest. Then which one should you choose among these four ? That you will learn in Part 10 - Model Selection. </p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Random-Forest-Regression/" itemprop="url">
                  Random Forest Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:17:33+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageRandom_forest.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-6"><a href="#Machine-Learning-A-Z-Part2-6" class="headerlink" title="Machine Learning A-Z Part2 - 6"></a>Machine Learning A-Z Part2 - 6</h1><h2 id="Random-Forest-Regression"><a href="#Random-Forest-Regression" class="headerlink" title="Random Forest Regression"></a>Random Forest Regression</h2><h3 id="Ensemble-Learning"><a href="#Ensemble-Learning" class="headerlink" title="Ensemble Learning"></a>Ensemble Learning</h3><p><em>Ensemble Learning</em>理念是把很多种算法结合在一起，或是把同一种算法在不同的数据上重复很多次，让机器学习的计算效果更好。</p>
<p>事实上我们要使用的随机森林算法对象也是<code>sklearn.ensemble</code> Library 中的对象。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest1.png" alt="Random Forest Intuition"></p>
<p>随机森林算法经过运算会得到很多的决策树，而不是一个。当然了，用来计算生成一颗决策树的数据也并非全体数据，那样的话得到的每颗决策树都是一样的，随机森林也就没什么意义了。<em>森林</em>指的是产生很多颗决策树，<em>随机</em>指的就是每次选取一部分数据用来运算，产生很多颗不同的‘树’。</p>
<p>当数据落在某个区域的时候就会返回多个决策树的预测的综合值，而不是单单一个决策树。<strong>这会让模型的预测更稳健更可靠，不再那么容易受到离群值的影响。</strong></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h4><p>和之前一样，还是三步走：</p>
<ol>
<li>从<code>sklearn.ensemble</code>中导入<code>RandomForestRegressor</code> Class</li>
<li>建立<code>RandomForestRegressor</code>实例</li>
<li><code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">regressor = RandomForestRegressor(n_estimators=<span class="number">300</span>, random_state=<span class="number">0</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest4.png" alt="fit"></p>
<p><strong>以下是Random Forest Class 的 Doc</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest2.png" alt="Random Forest doc1"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest3.png" alt="Random Forest doc2"></p>
<p>其中<code>n_estimators=</code>是用来调整建立多少颗决策树的参数，<code>random_state=</code>指的则是如何随机选取数据。</p>
<h4 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h4><p>由于随机森林算法不需要对数据进行<code>feature scaling</code>，所以直接使用<code>predict()</code>进行预测就好了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = regressor.predict(<span class="number">6.5</span>)</span><br></pre></td></tr></table></figure>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>保持先前的代码不动就可以画出随机森林的图像。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forestplot.png" alt="Random Forest Plot"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X_grid = np.arange(min(X), max(X), <span class="number">0.01</span>)</span><br><span class="line">X_grid = X_grid.reshape((len(X_grid), <span class="number">1</span>))</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Random Forest Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="建立更多的决策树，随机森林模型就会变得更平滑吗？"><a href="#建立更多的决策树，随机森林模型就会变得更平滑吗？" class="headerlink" title="建立更多的决策树，随机森林模型就会变得更平滑吗？"></a>建立更多的决策树，随机森林模型就会变得更平滑吗？</h4><p>这个问题是我们比较关心的，因为在我们的直觉中，越平滑好像就预测的越准，毕竟每个X轴上的值对应的预测值都是不一样的，更合情合理嘛。</p>
<p>但是对于有这种想法的人来说，随机森林恐怕要让他们失望了，因为随着随机森林建立的决策树数目的增加，模型的图像并不会变得“那么”平滑，它的图像看起来更像是比一颗决策树的图像多了那么几个“台阶”（对于一维特征值来说）。</p>
<p>这是因为随着决策树的增多，难免会选取到差不多的数据，数据的分类的边缘——也就是决策树的台阶，很多都会重合了。</p>
<p>虽然图像看起来并不那么平滑，但是随机森林在使用当中预测的值还是很准的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Decision-Tree-Regression/" itemprop="url">
                  Decision Tree Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T15:16:38+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageDecision_Tree_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-5"><a href="#Machine-Learning-A-Z-Part2-5" class="headerlink" title="Machine Learning A-Z Part2 - 5"></a>Machine Learning A-Z Part2 - 5</h1><h2 id="Decision-Tree-Regression"><a href="#Decision-Tree-Regression" class="headerlink" title="Decision Tree Regression"></a>Decision Tree Regression</h2><h3 id="Decision-Tree-Intuition"><a href="#Decision-Tree-Intuition" class="headerlink" title="Decision Tree Intuition"></a>Decision Tree Intuition</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree1.png" alt="two kind"></p>
<p>有两种决策树模型，一种是<em>Classification</em>另一种是<em>Regression</em>，两种决策树原理不同，这次主要学的是后者。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree.png" alt="simple example"><br>说的简单通俗一些，<em>Decision Tree</em>就是将数据切根据特征值切分成不同的区域，如果一个需要预测的数据掉在了某个区域里，就取一个区域中所有数据的平均值作为模型的预测值。</p>
<p>虽然讲起来很简单，但是运算的原理还是很高深的，这里先不深入，等我深入学习了statistical learning modle后再来update。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h4><p>现在已经逐渐习惯了python的回归模型建模，都是从<code>sklearn</code>的某个module中导入对应的<code>class</code>然后创建一个<code>regressor</code> instance，最后<code>fit()</code>到训练集上，回归模型就算创建完毕了。</p>
<p>建立Decision Tree需要用到的是<code>sklearn.tree</code>中的<code>DecisionTreeRegressor</code> class。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">regressor = DecisionTreeRegressor(random_state = <span class="number">0</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree2.png" alt="DecisionTreeRegressor"></p>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>和之前差不多，绘制Decision Tree模型是先把数据用散点图绘制出来，然后再把预测值画出来加到图上用线段表示作为模型。<em>Decision Tree</em>模型在一维的时候呈现出阶梯的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Decision Tree Regression results (for higher resolution and smoother curve)</span></span><br><span class="line">X_grid = np.arange(min(X.values), max(X.values), <span class="number">0.01</span>)</span><br><span class="line">X_grid = X_grid.reshape((len(X_grid), <span class="number">1</span>))</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Decision Tree Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree_Regression_Plot2.png" alt="Right Plot"></p>
<h4 id="Decision-Tree可视化的问题"><a href="#Decision-Tree可视化的问题" class="headerlink" title="Decision Tree可视化的问题"></a>Decision Tree可视化的问题</h4><p>我们绘制之前的线性模型的时候只要用下列代码就可以了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Decision Tree Regression results</span></span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, regressor.predict(X), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree_Regression_Plot1.png" alt="Incorrect Plot"></p>
<p>发现得到的图表中<em>Decision Tree</em>是一条<strong>连续的倾斜的</strong>线。这不符合Decision Tree模型预测值，Decision Tree是在某一个区域内（在这个数据集中，因为特征值只有一个维度，就是在X上取不同的区间）然后取该区域的平均值作为所有点的预测值。但是图上却不是这样，在一个区域内的预测值是不同的。</p>
<p>这个问题的原因所在就是我们只画了1到10的十个点的预测值，不同的点之间并没有点绘制出来，<code>matplotlib</code>只能用线段将两个点连起来，所以就出现了倾斜的线。这种模型与之前的两种模型都不同，既不是<em>Linear</em>也不是<em>Continuous</em>，是<em>Non-Linear &amp; Non-continous</em>模型。</p>
<p>对症下药，解决这个问题的方法就是将更多的点绘制出来，所以新建一个数列，把数据间隔变小，有更多的中间值，这样绘制出来才能看到正确的Decision Tree模型。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Support-Vector-Regression/" itemprop="url">
                  Support Vector Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T15:07:32+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageSupport_Vector_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-4"><a href="#Machine-Learning-A-Z-Part2-4" class="headerlink" title="Machine Learning A-Z Part2 - 4"></a>Machine Learning A-Z Part2 - 4</h1><h2 id="Support-Vector-Regression-SVR"><a href="#Support-Vector-Regression-SVR" class="headerlink" title="Support Vector Regression(SVR)"></a>Support Vector Regression(SVR)</h2><h3 id="Support-Vector-Regression-Intuition"><a href="#Support-Vector-Regression-Intuition" class="headerlink" title="Support Vector Regression Intuition"></a>Support Vector Regression Intuition</h3><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h4><p><em>SVR</em>不能像之前的线性回归模型中那样直接把训练集数据放入模型中进行建模。因为<strong>LinearRegressor</strong>会帮助我们进行<strong>Feature Scaling</strong>，但是<strong>SVR</strong>就不行了，所以我们要自己先对数据进行<strong>Feature Scaling</strong>。</p>
<p>再回忆一下，从<code>sklearn.preprocessing</code> Library中导入<code>StandardScaler</code> class。然后分别创建训练集的特征集标准化对象(<code>sc_X</code>)和预测值标准化对象(<code>sc_y</code>)，分别<code>fit_transform()</code>到各自的数据上，这样<strong>Feature Scaling</strong>就结束了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X = sc_X.fit_transform(X)</span><br><span class="line">sc_y = StandardScaler()</span><br><span class="line">y = sc_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression1.png" alt="Preprocessing Warning"></p>
<blockquote>
<p>这里会出现很多的Warnings，但是都是提醒数据格式将会被转换成float，并没有什么关系。</p>
</blockquote>
<h4 id="Fitting"><a href="#Fitting" class="headerlink" title="Fitting"></a>Fitting</h4><p>建立<em>SVR</em>模型需要用到<code>sklearn.svm</code> Library中的<code>SVR</code> class。设置对应的参数，然后<code>fit()</code>即可。</p>
<p><em>SVR</em> class的doc：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression4.png" alt="svr doc1"><br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression3.png" alt="svr doc2"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting the SVR Model to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line">regressor = SVR(kernel=<span class="string">'rbf'</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression2.png" alt="Fittting"></p>
<h4 id="Predicting"><a href="#Predicting" class="headerlink" title="Predicting"></a>Predicting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(np.array([[<span class="number">6.5</span>]]))))</span><br></pre></td></tr></table></figure>
<p>也许写成这样更清晰</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_pred = sc_y.inverse_transform(</span><br><span class="line">            regressor.predict(</span><br><span class="line">                sc_X.transform(</span><br><span class="line">                    np.array([[<span class="number">6.5</span>]])</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><strong>从里层到外层</strong>依次为：</p>
<ol>
<li>将希望预测的数据 6.5 转换成<code>numpy</code>中的一行一列<code>matrix</code>对象（可能是因为<code>transform()</code> method不支持 scala。)</li>
<li>传入标准化对象中进行<em>Feature Scaling</em></li>
<li>将标准化后的数据传入模型中进行预测</li>
<li>将预测的值<strong>反标准化</strong>(<code>inverse_transform()</code>)，还原成正常的预测值，而不是<code>0.3</code>、<code>2.1</code>之类的数字。</li>
</ol>
<h4 id="Visualising"><a href="#Visualising" class="headerlink" title="Visualising"></a>Visualising</h4><p>绘图和之前没有什么区别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the SVR results</span></span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, regressor.predict(X), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression_Plot.png" alt="Plot1"></p>
<p>可以看到绘制的图形并不是十分的平滑，为了让模型绘制的更准确，<strong>可以创建新的序列，提高数据的密度，绘制更多的点</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the SVR results (for higher resolution and smoother curve)</span></span><br><span class="line">X_grid = np.arange(min(X), max(X), <span class="number">0.1</span>)</span><br><span class="line">X_grid = pd.DataFrame(X_grid)</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (SVR Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression_Plot2.png" alt="Plot 2"></p>
<blockquote>
<p>关于为什么模型预测的最后一个值会那么小，那是因为最后一个数据点离其他的数据太远了，SVR模型把这个数据点当做了异常值，就给忽略了。</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Polynomial-Linear-Regression/" itemprop="url">
                  Polynomial Linear Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T11:14:09+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨-Machine Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimagePoly_Linear_Regression-1.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-3"><a href="#Machine-Learning-A-Z-Part2-3" class="headerlink" title="Machine Learning A-Z Part2 - 3"></a>Machine Learning A-Z Part2 - 3</h1><h2 id="Polynomial-Linear-Regression"><a href="#Polynomial-Linear-Regression" class="headerlink" title="Polynomial Linear Regression"></a>Polynomial Linear Regression</h2><h3 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h3><p><em>Polynomial Linear Regression</em>和<em>Multiple Linear Regression</em>的最主要区别就是，<em>Polynomial Linear Regression</em>在变量<code>x</code>上引入了次方的概念，让模型可以匹配更复杂的数据分布形式。</p>
<h4 id="Why-is-Polynomial-model-still-called-“Linear”"><a href="#Why-is-Polynomial-model-still-called-“Linear”" class="headerlink" title="Why is Polynomial model still called “Linear”?"></a>Why is Polynomial model still called “Linear”?</h4><p>这是因为在模型构建的过程当中X值我们是已知的，未知的是各个<code>X</code>之前的变量<code>b</code>。所以在未求解出<code>b</code>系数之前，模型还是关于<code>b</code>的线性方程。</p>
<p>如果将方程改为</p>
<p>$y = b<em>{0} + b</em>{1}x<em>{1} / b</em>{2}x_{2}$</p>
<p>那么这个方程就不再是线性回归模型了。</p>
<h3 id="何时使用Polynomial-Linear-Regression-model"><a href="#何时使用Polynomial-Linear-Regression-model" class="headerlink" title="何时使用Polynomial Linear Regression model?"></a>何时使用<em>Polynomial Linear Regression</em> model?</h3><p>事实上没有什么数据结构是一看就知道是要用线性模型还是用多项式模型，我觉得最方便的工具应该就是<strong>可视化</strong>。可以先<strong>在探索数据的时候绘制散点图，这样可以观察数据的分布</strong>。如果你明显看到他不呈直线形式分布，那么可以考虑多项式。或者第二个方法就是<strong>试错</strong>，可以<strong>先建立线性模型，将模型和数据都可视化</strong>，如果模型预测值在图上显示很不准确，那么可以考虑使用多项式模型。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h4><p>和之前差不多，这里也要引入<code>sklearn.linear_model</code>的<code>LinearRegression</code> class。但是在<code>fit()</code>的时候需要注意不能直接把训练集放入，需要进行适当的转化。</p>
<h5 id="错误的fit方式"><a href="#错误的fit方式" class="headerlink" title="错误的fit方式"></a>错误的fit方式</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting Linear Regression to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br></pre></td></tr></table></figure>
<p>这样只能得到一个简单线性模型或者多重线性模型，因为我们还没有对变量进行任何的转换，<code>LinearRegression()</code>也没有参数设置构建的模型为<em>Polynomial model</em>,想要正确的构建模型我们需要其他的Library来帮忙。</p>
<h5 id="正确——将变量转为多次方"><a href="#正确——将变量转为多次方" class="headerlink" title="正确——将变量转为多次方"></a>正确——<strong>将变量转为多次方</strong></h5><p>下面的代码才是构建<em>Polynomial model</em>的正确方式。这里我们用到了<code>sklearn.preprocessing</code>中的<code>PolynomialFeatures</code> class。从Library的名字也可以看出，我们是在建模之前先对数据进行处理，将原先的数据集按照我们的要求把变量转变为多次方。</p>
<p>这里我们先创建一个<code>PolynomialFeatures</code> instance，指定进行转换的次方，然后再<code>fit_transform()</code>到训练集上。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Poly_Linear_Regression-2.jpg" alt="Ploy preprocessing"></p>
<p>从图上我们可以看到，<code>PolynomialFeatures</code>不是简单的返回一个进行平方（或指定次方）的数据，它还会给数据加上一列常数项，让线性模型知道还需要有一个常数项。</p>
<p>数据预处理结束后的步骤就和之前是一样的，创建一个<code>LinearRegression</code> instance，然后<code>fit()</code>到处理过的训练集上，模型就算建立完成了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting Linear Regression to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">poly_reg = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_poly = poly_reg.fit_transform(X)</span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X_poly, y)</span><br></pre></td></tr></table></figure>
<h4 id="利用模型预测"><a href="#利用模型预测" class="headerlink" title="利用模型预测"></a>利用模型预测</h4><p>和建模一样的，<strong>我们在预测的时候也不能想当然的把测试集直接丢进去，我们需要对测试集进行同样的次方转换处理才行。</strong>这里用之前构建的次方转换对象<code>fit_transform()</code>测试集，然后再进行<code>predict()</code>，这样预测出来的数据才是正确的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Incorrect Predicting</span></span><br><span class="line">lin_reg_2.predict(<span class="number">6.5</span>)</span><br><span class="line"><span class="comment"># Predicting a new result with Polynomial Regression</span></span><br><span class="line">lin_reg_2.predict(poly_reg.fit_transform(<span class="number">6.5</span>))</span><br></pre></td></tr></table></figure>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>与之前的线性模型不同的就是需要考虑到<strong>次方转换</strong>的问题，其他的改动是因为想要绘制更多的点，让线段能够更加的平滑。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Poly_Linear_Regression_Plot.png" alt="Plot"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Polynomial Regression results</span></span><br><span class="line">X_grid = np.arange(min(X.values), max(X.values), <span class="number">0.1</span>)</span><br><span class="line">X_grid = pd.DataFrame(X_grid)</span><br><span class="line">plt.scatter(X, y, color=<span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color=<span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff &#123;Polynomial Regression&#125;'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xvrvp.com1.z0.glb.clouddn.com/AlexanderLiu.jpg"
               alt="AlexanderLiu" />
          <p class="site-author-name" itemprop="name">AlexanderLiu</p>
          <p class="site-description motion-element" itemprop="description">不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">43</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AlexanderLiu</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  

  

</body>
</html>
