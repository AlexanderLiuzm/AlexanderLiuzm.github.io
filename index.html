<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">
<meta property="og:type" content="website">
<meta property="og:title" content="牧牧闻叨">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="牧牧闻叨">
<meta property="og:description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="牧牧闻叨">
<meta name="twitter:description" content="不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> 牧牧闻叨 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">牧牧闻叨</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">整理心中的知识体系，让自己变得更好</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Logistic-Regression/" itemprop="url">
                  Logistic Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:34:13+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageLogistic_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part3-1"><a href="#Machine-Learning-A-Z-Part3-1" class="headerlink" title="Machine Learning A-Z Part3 - 1"></a>Machine Learning A-Z Part3 - 1</h1><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><h3 id="Logistic-Regression-Intuition"><a href="#Logistic-Regression-Intuition" class="headerlink" title="Logistic Regression Intuition"></a>Logistic Regression Intuition</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression1.png" alt="problem with linear regressor"><br><strong>有时候我们要预测的值并不是连续变量，可能是分类变量，比如一个顾客是会 买 还是 不买 某个商品。</strong>这种情况下我们使用线性回归就不太合适，不能很好的对情况进行预测，因为线性回归产生的预测值也是连续值，最大的问题就是，<strong>线性回归模型会产生超过1和小于0的预测值</strong>，这些预测值无法作为概率来理解，这让线性回归模型不适合预测分类变量这种情景。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression2.png" alt="Logistic1"></p>
<p>为了让特征值能使用连续变量，而预测值却限定在 0-1 之间，逻辑回归就出现了。逻辑回归也是预测连续变量，但是他的特点是能把预测值限定在0-1之间。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression3.png" alt="Logistic2"></p>
<p>这种模型预测的是分类变量的概率，<strong>通常还要有一个决策标准，即判定概率多上以上就判定为1，其余的判定为另一种分类变量</strong>。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h4><p>这次处理的数据大致结构如下：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_dataset.png" alt="dataset"></p>
<p>由于逻辑回归是使用连续变量来预测分类变量的，所以我们只需要选取元数据中的连续变量作为特征值即可。</p>
<p>在切割完数据之后，我们还需要对数据进行<em>Feature Scaling</em>处理，因为我们希望模型不要受到不同度量衡的影响，处理过的数据让数据更加准确。这里只需要对特征值进行标准化处理就可以了，预测值因为已经是分类变量，所以是不需要进行<em>Feature Scaling</em>的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Social_Network_Ads.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, <span class="number">2</span>:<span class="number">4</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">4</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.25</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="Fit-the-model"><a href="#Fit-the-model" class="headerlink" title="Fit the model"></a>Fit the model</h4><p>还是往常一样的三步走：</p>
<ol>
<li>从<code>sklearn.linear_model</code> import <code>LogisticRegression</code></li>
<li>建立一个<code>LogisticRegression</code>实例</li>
<li>将该对象实例<code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">classifier = LogisticRegression(random_state = <span class="number">0</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression4.png" alt="fit Logistic"></p>
<h4 id="Predict"><a href="#Predict" class="headerlink" title="Predict"></a>Predict</h4><p>利用模型进行预测也没有什么好多说的，没有什么不同，还是用模型的<code>predict()</code>方法即可，但是要注意<strong>我们在预处理的时候就把测试集的特征值先进行了标准化，如果我们预测的不是测试集，那么也需要先对数据进行标准化处理。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = classifier.predict(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="Making-the-confusion-matrix"><a href="#Making-the-confusion-matrix" class="headerlink" title="Making the confusion matrix"></a>Making the confusion matrix</h4><p>混淆矩阵是很清晰的展示分类模型的好坏的一个工具，它的原理就是建立一个矩阵，将数据真实的分类值和预测的分类值进行比较，有<code>(1, 1)</code> - 实际为真，预测为真; <code>(1, 0)</code> - 实际为真，预测为假 <strong>I类错误</strong>; <code>(0, 1)</code> - 实际为假，预测为真 <strong>II类错误</strong>; <code>(0, 0)</code> - 实际为假，预测为假 四种。</p>
<p>在python中，我们使用<code>sklearn.metrics</code>中的<code>confusion_matrix</code>对象来创建混淆矩阵。需要输入的系数有：<code>y_true=</code>代表真正值的数据集(array)；<code>y_pred=</code>预测值的集合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">cm = confusion_matrix(y_true=y_test, y_pred=y_pred)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/cm.png" alt="confusion_matrix"></p>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>这次的可视化比较复杂，但也因为特征值是二维数据，所以和之前的一维数据相比，绘制的图形也更为直观，更为有趣。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import color map class</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="comment"># copy X_test and y_test array, simplify reuse process</span></span><br><span class="line">X_set, y_set = X_test, y_test</span><br><span class="line"><span class="comment"># Create array used for total panel and axis</span></span><br><span class="line"><span class="comment"># make range a little wider than data range of dataset</span></span><br><span class="line"><span class="comment"># avoid data fall into edge of plot, make plot looks clear</span></span><br><span class="line">X1, X2 = np.meshgrid(np.arange(start=X_set[:, <span class="number">0</span>].min() <span class="number">-1</span>, stop=X_set[:, <span class="number">0</span>].max() + <span class="number">1</span>, step=<span class="number">0.01</span>),</span><br><span class="line">                     np.arange(start=X_set[:, <span class="number">1</span>].min() <span class="number">-1</span>, stop=X_set[:, <span class="number">1</span>].max() + <span class="number">1</span>, step=<span class="number">0.01</span>))</span><br><span class="line"><span class="comment"># draw a panel pixel by pixel</span></span><br><span class="line">plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),</span><br><span class="line">             alpha=<span class="number">0.75</span>, cmap=ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>)))</span><br><span class="line"><span class="comment"># limit plot's axis</span></span><br><span class="line">plt.xlim(X1.min(), X1.max())</span><br><span class="line">plt.ylim(X2.min(), X2.max())</span><br><span class="line"><span class="comment"># making scatter plot</span></span><br><span class="line"><span class="comment"># use y as index to loop all data and fill in different colors</span></span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> enumerate(np.unique(y_set)):</span><br><span class="line">    plt.scatter(X_set[y_set == j, <span class="number">0</span>], X_set[y_set == j, <span class="number">1</span>],</span><br><span class="line">                c = ListedColormap((<span class="string">'red'</span>, <span class="string">'green'</span>))(i), label = j)</span><br><span class="line"><span class="comment"># make some additional decoration</span></span><br><span class="line">plt.title(<span class="string">'Logistic Regression (Test Set)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Age'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Estimated Salary'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_plot_test.png" alt="plot test"></p>
<p>同样的方法也可以绘制训练集的图</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Classification/Logistic_Regression_plot_train.png" alt="plot train"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Evaluating-Regression-Models-Performance/" itemprop="url">
                  Evaluating Regression Models Performance
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:27:38+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageEvaluating_Regressor.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-7"><a href="#Machine-Learning-A-Z-Part2-7" class="headerlink" title="Machine Learning A-Z Part2 - 7"></a>Machine Learning A-Z Part2 - 7</h1><h2 id="Evaluating-Regression-Models-Performance"><a href="#Evaluating-Regression-Models-Performance" class="headerlink" title="Evaluating Regression Models Performance"></a>Evaluating Regression Models Performance</h2><h3 id="两个判断模型好坏的指标"><a href="#两个判断模型好坏的指标" class="headerlink" title="两个判断模型好坏的指标"></a>两个判断模型好坏的指标</h3><h3 id="R-Square"><a href="#R-Square" class="headerlink" title="R Square"></a>R Square</h3><p><strong>R方</strong>是我们比较熟悉的一个统计指标了，它的大小显示了一个模型的优劣程度。他的公式是</p>
<p>$SS<em>{res} = \sum(y</em>{i} - \hat y_{i})$</p>
<p>$SS<em>{tot} = \sum(y</em>{i} - \hat y_{avg})$</p>
<p>$R^{2} = 1 - \frac{SS<em>{res}}{SS</em>{tot}}$</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/R_squared1.png" alt="R Square"></p>
<p>用平均值来作为预测值是每个人都可以想得到的，没有什么技术含量，作为比较的基准。我们建立的模型的残差作为比较值，放入$R^{2}$中进行计算，模型效果越好，残差越小，$R^{2}$越大；相反的，模型越差，残差越大，$R^{2}$越小。</p>
<p><strong>所以，模型越好，$R^{2}$越大，模型越差，$R^{2}$越小。</strong></p>
<h3 id="Adjusted-R-Square"><a href="#Adjusted-R-Square" class="headerlink" title="Adjusted R Square"></a>Adjusted R Square</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com/Adj_R_squared1.png" alt="Problem with R Square"><br>但是R方有一个致命的缺点——随着变量个数的增加，R方只会上升，不会下降。之前学习R语言的时候老师也提到过，之前在建立模型只看R方判断的前提下，很多高校的教授为了超高的R方，就在模型中加入各种变量，把模型公式弄得很长很复杂，但是其中加入的变量有些根本和预测值没有什么关系，仅仅是放进来增加R方用的。</p>
<p>$$Adj \ R^{2} = 1 - (1 - R^{2})\frac{n - 1}{n -p - 1}$$</p>
<blockquote>
<p><strong>n</strong> is the sample size<br><strong>p</strong> is the total number of explanatory variables in the model (not including the constant term)</p>
</blockquote>
<p>为了避免这种情况，人们发明了<strong>调整R方</strong>，从本质上来说，它和R方最大的不同就是<strong>调整R方中加入了惩罚系数——即$\frac{n - 1}{n -p - 1}$</strong>。当加入的变量相关性并不是那么显著的时候，惩罚系数的削减效用会占主要作用，此时调整R方会减小。因此也就避免了盲目加入过多变量的现象，给了人们更直观的判断依据。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Adj_R_squared2.png" alt="Adj R Square"></p>
<h3 id="不要掉入相关系数的陷阱"><a href="#不要掉入相关系数的陷阱" class="headerlink" title="不要掉入相关系数的陷阱"></a>不要掉入相关系数的陷阱</h3><p>有的人认为一个变量的重要与否主要要看他的相关系数是否很大，大的话就很有用，就很好。其实不是这样的，因为相关系数的大小只是单位变动的体现。<strong>也就是说，相关系数和单位有很大的关系，当度量衡变小的时候，相关系数就相应的放大，度量衡变大的时候，先关系数就相应的缩小。</strong></p>
<p>举例来说，我们观察气温和商场营业额的模型，如果商场营业额用万元来算，那么相关系数就会很小，可能每摄氏度的变化给营业额造成的影响才1或者0.1，但是<strong>那可是1万元啊！</strong>相对的，如果用元来衡量的话，那相关系数就会变成10000，看起来很大吧？可是表达的意思却没什么不同，还是一个意思。<strong>一个是1万元，一个是10000元。</strong></p>
<h3 id="回归模型各有什么优劣？"><a href="#回归模型各有什么优劣？" class="headerlink" title="回归模型各有什么优劣？"></a>回归模型各有什么优劣？</h3><p>下面这张图可以总结性的概括过去学习的回归模型的优势和劣势：</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Regression-Pros-Cons.jpg" alt="pros-cons"></p>
<h3 id="如何选择该使用哪个模型？"><a href="#如何选择该使用哪个模型？" class="headerlink" title="如何选择该使用哪个模型？"></a>如何选择该使用哪个模型？</h3><blockquote>
<p>First, you need to figure out whether your problem is linear or non linear. You will learn how to do that in Part 10 - Model Selection. Then:</p>
<p>If your problem is linear, you should go for Simple Linear Regression if you only have one feature, and Multiple Linear Regression if you have several features.</p>
<p>If your problem is non linear, you should go for Polynomial Regression, SVR, Decision Tree or Random Forest. Then which one should you choose among these four ? That you will learn in Part 10 - Model Selection. </p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Random-Forest-Regression/" itemprop="url">
                  Random Forest Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T20:17:33+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageRandom_forest.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-6"><a href="#Machine-Learning-A-Z-Part2-6" class="headerlink" title="Machine Learning A-Z Part2 - 6"></a>Machine Learning A-Z Part2 - 6</h1><h2 id="Random-Forest-Regression"><a href="#Random-Forest-Regression" class="headerlink" title="Random Forest Regression"></a>Random Forest Regression</h2><h3 id="Ensemble-Learning"><a href="#Ensemble-Learning" class="headerlink" title="Ensemble Learning"></a>Ensemble Learning</h3><p><em>Ensemble Learning</em>理念是把很多种算法结合在一起，或是把同一种算法在不同的数据上重复很多次，让机器学习的计算效果更好。</p>
<p>事实上我们要使用的随机森林算法对象也是<code>sklearn.ensemble</code> Library 中的对象。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest1.png" alt="Random Forest Intuition"></p>
<p>随机森林算法经过运算会得到很多的决策树，而不是一个。当然了，用来计算生成一颗决策树的数据也并非全体数据，那样的话得到的每颗决策树都是一样的，随机森林也就没什么意义了。<em>森林</em>指的是产生很多颗决策树，<em>随机</em>指的就是每次选取一部分数据用来运算，产生很多颗不同的‘树’。</p>
<p>当数据落在某个区域的时候就会返回多个决策树的预测的综合值，而不是单单一个决策树。<strong>这会让模型的预测更稳健更可靠，不再那么容易受到离群值的影响。</strong></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h4><p>和之前一样，还是三步走：</p>
<ol>
<li>从<code>sklearn.ensemble</code>中导入<code>RandomForestRegressor</code> Class</li>
<li>建立<code>RandomForestRegressor</code>实例</li>
<li><code>fit()</code>到训练集上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">regressor = RandomForestRegressor(n_estimators=<span class="number">300</span>, random_state=<span class="number">0</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest4.png" alt="fit"></p>
<p><strong>以下是Random Forest Class 的 Doc</strong></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest2.png" alt="Random Forest doc1"></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forest3.png" alt="Random Forest doc2"></p>
<p>其中<code>n_estimators=</code>是用来调整建立多少颗决策树的参数，<code>random_state=</code>指的则是如何随机选取数据。</p>
<h4 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h4><p>由于随机森林算法不需要对数据进行<code>feature scaling</code>，所以直接使用<code>predict()</code>进行预测就好了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = regressor.predict(<span class="number">6.5</span>)</span><br></pre></td></tr></table></figure>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>保持先前的代码不动就可以画出随机森林的图像。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Random_Forestplot.png" alt="Random Forest Plot"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X_grid = np.arange(min(X), max(X), <span class="number">0.01</span>)</span><br><span class="line">X_grid = X_grid.reshape((len(X_grid), <span class="number">1</span>))</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Random Forest Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="建立更多的决策树，随机森林模型就会变得更平滑吗？"><a href="#建立更多的决策树，随机森林模型就会变得更平滑吗？" class="headerlink" title="建立更多的决策树，随机森林模型就会变得更平滑吗？"></a>建立更多的决策树，随机森林模型就会变得更平滑吗？</h4><p>这个问题是我们比较关心的，因为在我们的直觉中，越平滑好像就预测的越准，毕竟每个X轴上的值对应的预测值都是不一样的，更合情合理嘛。</p>
<p>但是对于有这种想法的人来说，随机森林恐怕要让他们失望了，因为随着随机森林建立的决策树数目的增加，模型的图像并不会变得“那么”平滑，它的图像看起来更像是比一颗决策树的图像多了那么几个“台阶”（对于一维特征值来说）。</p>
<p>这是因为随着决策树的增多，难免会选取到差不多的数据，数据的分类的边缘——也就是决策树的台阶，很多都会重合了。</p>
<p>虽然图像看起来并不那么平滑，但是随机森林在使用当中预测的值还是很准的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Decision-Tree-Regression/" itemprop="url">
                  Decision Tree Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T15:16:38+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageDecision_Tree_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-5"><a href="#Machine-Learning-A-Z-Part2-5" class="headerlink" title="Machine Learning A-Z Part2 - 5"></a>Machine Learning A-Z Part2 - 5</h1><h2 id="Decision-Tree-Regression"><a href="#Decision-Tree-Regression" class="headerlink" title="Decision Tree Regression"></a>Decision Tree Regression</h2><h3 id="Decision-Tree-Intuition"><a href="#Decision-Tree-Intuition" class="headerlink" title="Decision Tree Intuition"></a>Decision Tree Intuition</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree1.png" alt="two kind"></p>
<p>有两种决策树模型，一种是<em>Classification</em>另一种是<em>Regression</em>，两种决策树原理不同，这次主要学的是后者。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree.png" alt="simple example"><br>说的简单通俗一些，<em>Decision Tree</em>就是将数据切根据特征值切分成不同的区域，如果一个需要预测的数据掉在了某个区域里，就取一个区域中所有数据的平均值作为模型的预测值。</p>
<p>虽然讲起来很简单，但是运算的原理还是很高深的，这里先不深入，等我深入学习了statistical learning modle后再来update。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h4><p>现在已经逐渐习惯了python的回归模型建模，都是从<code>sklearn</code>的某个module中导入对应的<code>class</code>然后创建一个<code>regressor</code> instance，最后<code>fit()</code>到训练集上，回归模型就算创建完毕了。</p>
<p>建立Decision Tree需要用到的是<code>sklearn.tree</code>中的<code>DecisionTreeRegressor</code> class。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">regressor = DecisionTreeRegressor(random_state = <span class="number">0</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree2.png" alt="DecisionTreeRegressor"></p>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>和之前差不多，绘制Decision Tree模型是先把数据用散点图绘制出来，然后再把预测值画出来加到图上用线段表示作为模型。<em>Decision Tree</em>模型在一维的时候呈现出阶梯的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Decision Tree Regression results (for higher resolution and smoother curve)</span></span><br><span class="line">X_grid = np.arange(min(X.values), max(X.values), <span class="number">0.01</span>)</span><br><span class="line">X_grid = X_grid.reshape((len(X_grid), <span class="number">1</span>))</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Decision Tree Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree_Regression_Plot2.png" alt="Right Plot"></p>
<h4 id="Decision-Tree可视化的问题"><a href="#Decision-Tree可视化的问题" class="headerlink" title="Decision Tree可视化的问题"></a>Decision Tree可视化的问题</h4><p>我们绘制之前的线性模型的时候只要用下列代码就可以了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Decision Tree Regression results</span></span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, regressor.predict(X), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Decision_Tree_Regression_Plot1.png" alt="Incorrect Plot"></p>
<p>发现得到的图表中<em>Decision Tree</em>是一条<strong>连续的倾斜的</strong>线。这不符合Decision Tree模型预测值，Decision Tree是在某一个区域内（在这个数据集中，因为特征值只有一个维度，就是在X上取不同的区间）然后取该区域的平均值作为所有点的预测值。但是图上却不是这样，在一个区域内的预测值是不同的。</p>
<p>这个问题的原因所在就是我们只画了1到10的十个点的预测值，不同的点之间并没有点绘制出来，<code>matplotlib</code>只能用线段将两个点连起来，所以就出现了倾斜的线。这种模型与之前的两种模型都不同，既不是<em>Linear</em>也不是<em>Continuous</em>，是<em>Non-Linear &amp; Non-continous</em>模型。</p>
<p>对症下药，解决这个问题的方法就是将更多的点绘制出来，所以新建一个数列，把数据间隔变小，有更多的中间值，这样绘制出来才能看到正确的Decision Tree模型。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Support-Vector-Regression/" itemprop="url">
                  Support Vector Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T15:07:32+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageSupport_Vector_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-4"><a href="#Machine-Learning-A-Z-Part2-4" class="headerlink" title="Machine Learning A-Z Part2 - 4"></a>Machine Learning A-Z Part2 - 4</h1><h2 id="Support-Vector-Regression-SVR"><a href="#Support-Vector-Regression-SVR" class="headerlink" title="Support Vector Regression(SVR)"></a>Support Vector Regression(SVR)</h2><h3 id="Support-Vector-Regression-Intuition"><a href="#Support-Vector-Regression-Intuition" class="headerlink" title="Support Vector Regression Intuition"></a>Support Vector Regression Intuition</h3><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h4><p><em>SVR</em>不能像之前的线性回归模型中那样直接把训练集数据放入模型中进行建模。因为<strong>LinearRegressor</strong>会帮助我们进行<strong>Feature Scaling</strong>，但是<strong>SVR</strong>就不行了，所以我们要自己先对数据进行<strong>Feature Scaling</strong>。</p>
<p>再回忆一下，从<code>sklearn.preprocessing</code> Library中导入<code>StandardScaler</code> class。然后分别创建训练集的特征集标准化对象(<code>sc_X</code>)和预测值标准化对象(<code>sc_y</code>)，分别<code>fit_transform()</code>到各自的数据上，这样<strong>Feature Scaling</strong>就结束了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X = sc_X.fit_transform(X)</span><br><span class="line">sc_y = StandardScaler()</span><br><span class="line">y = sc_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression1.png" alt="Preprocessing Warning"></p>
<blockquote>
<p>这里会出现很多的Warnings，但是都是提醒数据格式将会被转换成float，并没有什么关系。</p>
</blockquote>
<h4 id="Fitting"><a href="#Fitting" class="headerlink" title="Fitting"></a>Fitting</h4><p>建立<em>SVR</em>模型需要用到<code>sklearn.svm</code> Library中的<code>SVR</code> class。设置对应的参数，然后<code>fit()</code>即可。</p>
<p><em>SVR</em> class的doc：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression4.png" alt="svr doc1"><br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression3.png" alt="svr doc2"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting the SVR Model to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line">regressor = SVR(kernel=<span class="string">'rbf'</span>)</span><br><span class="line">regressor.fit(X, y)</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression2.png" alt="Fittting"></p>
<h4 id="Predicting"><a href="#Predicting" class="headerlink" title="Predicting"></a>Predicting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(np.array([[<span class="number">6.5</span>]]))))</span><br></pre></td></tr></table></figure>
<p>也许写成这样更清晰</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_pred = sc_y.inverse_transform(</span><br><span class="line">            regressor.predict(</span><br><span class="line">                sc_X.transform(</span><br><span class="line">                    np.array([[<span class="number">6.5</span>]])</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><strong>从里层到外层</strong>依次为：</p>
<ol>
<li>将希望预测的数据 6.5 转换成<code>numpy</code>中的一行一列<code>matrix</code>对象（可能是因为<code>transform()</code> method不支持 scala。)</li>
<li>传入标准化对象中进行<em>Feature Scaling</em></li>
<li>将标准化后的数据传入模型中进行预测</li>
<li>将预测的值<strong>反标准化</strong>(<code>inverse_transform()</code>)，还原成正常的预测值，而不是<code>0.3</code>、<code>2.1</code>之类的数字。</li>
</ol>
<h4 id="Visualising"><a href="#Visualising" class="headerlink" title="Visualising"></a>Visualising</h4><p>绘图和之前没有什么区别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the SVR results</span></span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, regressor.predict(X), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (Regression Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression_Plot.png" alt="Plot1"></p>
<p>可以看到绘制的图形并不是十分的平滑，为了让模型绘制的更准确，<strong>可以创建新的序列，提高数据的密度，绘制更多的点</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the SVR results (for higher resolution and smoother curve)</span></span><br><span class="line">X_grid = np.arange(min(X), max(X), <span class="number">0.1</span>)</span><br><span class="line">X_grid = pd.DataFrame(X_grid)</span><br><span class="line">plt.scatter(X, y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, regressor.predict(X_grid), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff (SVR Model)'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/SVR_Regression_Plot2.png" alt="Plot 2"></p>
<blockquote>
<p>关于为什么模型预测的最后一个值会那么小，那是因为最后一个数据点离其他的数据太远了，SVR模型把这个数据点当做了异常值，就给忽略了。</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Polynomial-Linear-Regression/" itemprop="url">
                  Polynomial Linear Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T11:14:09+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimagePoly_Linear_Regression-1.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-3"><a href="#Machine-Learning-A-Z-Part2-3" class="headerlink" title="Machine Learning A-Z Part2 - 3"></a>Machine Learning A-Z Part2 - 3</h1><h2 id="Polynomial-Linear-Regression"><a href="#Polynomial-Linear-Regression" class="headerlink" title="Polynomial Linear Regression"></a>Polynomial Linear Regression</h2><h3 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h3><p><em>Polynomial Linear Regression</em>和<em>Multiple Linear Regression</em>的最主要区别就是，<em>Polynomial Linear Regression</em>在变量<code>x</code>上引入了次方的概念，让模型可以匹配更复杂的数据分布形式。</p>
<h4 id="Why-is-Polynomial-model-still-called-“Linear”"><a href="#Why-is-Polynomial-model-still-called-“Linear”" class="headerlink" title="Why is Polynomial model still called “Linear”?"></a>Why is Polynomial model still called “Linear”?</h4><p>这是因为在模型构建的过程当中X值我们是已知的，未知的是各个<code>X</code>之前的变量<code>b</code>。所以在未求解出<code>b</code>系数之前，模型还是关于<code>b</code>的线性方程。</p>
<p>如果将方程改为</p>
<p>$y = b<em>{0} + b</em>{1} x<em>{1} / b</em>{2} x_{2}$</p>
<p>那么这个方程就不再是线性回归模型了。</p>
<h3 id="何时使用Polynomial-Linear-Regression-model"><a href="#何时使用Polynomial-Linear-Regression-model" class="headerlink" title="何时使用Polynomial Linear Regression model?"></a>何时使用<em>Polynomial Linear Regression</em> model?</h3><p>事实上没有什么数据结构是一看就知道是要用线性模型还是用多项式模型，我觉得最方便的工具应该就是<strong>可视化</strong>。可以先<strong>在探索数据的时候绘制散点图，这样可以观察数据的分布</strong>。如果你明显看到他不呈直线形式分布，那么可以考虑多项式。或者第二个方法就是<strong>试错</strong>，可以<strong>先建立线性模型，将模型和数据都可视化</strong>，如果模型预测值在图上显示很不准确，那么可以考虑使用多项式模型。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h4><p>和之前差不多，这里也要引入<code>sklearn.linear_model</code>的<code>LinearRegression</code> class。但是在<code>fit()</code>的时候需要注意不能直接把训练集放入，需要进行适当的转化。</p>
<h5 id="错误的fit方式"><a href="#错误的fit方式" class="headerlink" title="错误的fit方式"></a>错误的fit方式</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting Linear Regression to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br></pre></td></tr></table></figure>
<p>这样只能得到一个简单线性模型或者多重线性模型，因为我们还没有对变量进行任何的转换，<code>LinearRegression()</code>也没有参数设置构建的模型为<em>Polynomial model</em>,想要正确的构建模型我们需要其他的Library来帮忙。</p>
<h5 id="正确——将变量转为多次方"><a href="#正确——将变量转为多次方" class="headerlink" title="正确——将变量转为多次方"></a>正确——<strong>将变量转为多次方</strong></h5><p>下面的代码才是构建<em>Polynomial model</em>的正确方式。这里我们用到了<code>sklearn.preprocessing</code>中的<code>PolynomialFeatures</code> class。从Library的名字也可以看出，我们是在建模之前先对数据进行处理，将原先的数据集按照我们的要求把变量转变为多次方。</p>
<p>这里我们先创建一个<code>PolynomialFeatures</code> instance，指定进行转换的次方，然后再<code>fit_transform()</code>到训练集上。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Poly_Linear_Regression-2.jpg" alt="Ploy preprocessing"></p>
<p>从图上我们可以看到，<code>PolynomialFeatures</code>不是简单的返回一个进行平方（或指定次方）的数据，它还会给数据加上一列常数项，让线性模型知道还需要有一个常数项。</p>
<p>数据预处理结束后的步骤就和之前是一样的，创建一个<code>LinearRegression</code> instance，然后<code>fit()</code>到处理过的训练集上，模型就算建立完成了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting Linear Regression to the dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">poly_reg = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_poly = poly_reg.fit_transform(X)</span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X_poly, y)</span><br></pre></td></tr></table></figure>
<h4 id="利用模型预测"><a href="#利用模型预测" class="headerlink" title="利用模型预测"></a>利用模型预测</h4><p>和建模一样的，<strong>我们在预测的时候也不能想当然的把测试集直接丢进去，我们需要对测试集进行同样的次方转换处理才行。</strong>这里用之前构建的次方转换对象<code>fit_transform()</code>测试集，然后再进行<code>predict()</code>，这样预测出来的数据才是正确的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Incorrect Predicting</span></span><br><span class="line">lin_reg_2.predict(<span class="number">6.5</span>)</span><br><span class="line"><span class="comment"># Predicting a new result with Polynomial Regression</span></span><br><span class="line">lin_reg_2.predict(poly_reg.fit_transform(<span class="number">6.5</span>))</span><br></pre></td></tr></table></figure>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>与之前的线性模型不同的就是需要考虑到<strong>次方转换</strong>的问题，其他的改动是因为想要绘制更多的点，让线段能够更加的平滑。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Poly_Linear_Regression_Plot.png" alt="Plot"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Polynomial Regression results</span></span><br><span class="line">X_grid = np.arange(min(X.values), max(X.values), <span class="number">0.1</span>)</span><br><span class="line">X_grid = pd.DataFrame(X_grid)</span><br><span class="line">plt.scatter(X, y, color=<span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color=<span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Truth or Bluff &#123;Polynomial Regression&#125;'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Position level'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/20/Multiple-Linear-Regression/" itemprop="url">
                  Multiple Linear Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-20T08:18:55+08:00" content="2017-07-20">
              2017-07-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageMultiple_Linear_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-2"><a href="#Machine-Learning-A-Z-Part2-2" class="headerlink" title="Machine Learning A-Z Part2 - 2"></a>Machine Learning A-Z Part2 - 2</h1><h2 id="Multiple-Linear-Regression"><a href="#Multiple-Linear-Regression" class="headerlink" title="Multiple Linear Regression"></a>Multiple Linear Regression</h2><h3 id="模型概览"><a href="#模型概览" class="headerlink" title="模型概览"></a>模型概览</h3><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression1.png" alt="Describe Multiple Linear Regression"></p>
<p><em>Multiple Linear Regression</em>比起<em>Simple Linear Regression</em>就是增加了几个<strong>Independent Variables</strong>。虽然讲起来就是这么简单的事情，事实上这个模型变得更难形象化的理解了，如果仅仅是将变量增加到二维，那么我们得到的线性模型就是三维空间中的一个平面，用这个平面去预测一个个点的位置。但是如果增加到三个Independent Variables，甚至更多，那基本不太可能进行可视化了，我们只能将一个变量的系数抽象的理解为特定变量对预测值的贡献大小。</p>
<p>要建立多因子线性回归模型，数据要满足如下假设：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression2.png" alt="Assumptions"></p>
<p>该模型对数据主要有5个假设：</p>
<ol>
<li>预测值和特征值的是线性相关的（从模型的名字也可以看出，不是线性的如何匹配？）</li>
<li>同方差性<br>同方差性即误差项与独立变量（independent variable）之间相互独立, 并且误差项的分散(方差 Variance)必须等同即；Var(u|x)=σ^2</li>
<li>多元正态分布</li>
<li>误差独立</li>
<li>数据不能存在多重共线性问题</li>
</ol>
<p>很多时候我们会兴冲冲的拿着数据和代码就开始构建模型，希望看到一个漂亮的可视化图表。但是我们往往都忘记了检验一个数据集是否符合模型的基本假设是多么重要的事情。有的时候一个数据集可能根本不符合正态分布，但是我们硬要将数据套入一个<em>Multiple Linear Regression</em>，这种情况下无论我们费多大劲去筛选变量，去优化模型，到头来都是白费功夫。</p>
<p>我最近读了《Bad Data Handbook》，其中有一个学者专门强调了验证数据符合假设的重要性。他提到自己有一次在为电信公司构建客户拨打客服热线的模型，他拿到这个数据的时候不假思索的认为数据肯定符合泊松(<em>Poisson</em>)分布，因为很明显的，客户拨打电话这个情景完全符合泊松分布的三个假设：</p>
<ol>
<li>事件随机发生(<em>Events occur at a constant rate</em>)</li>
<li>每个事件都相互独立(<em>Events are independent of each other</em>)</li>
<li>事件不会同时发生(<em>Events do not occur simultaneously</em>)</li>
</ol>
<p>但是当他建模完成的时候才发现数据的分布根本不符合泊松分布，经过对数据集仔细的研究，他发现<strong>原来数据集中记载了很多在第一次拨打热线后回拨的电话，这些电话就是造成误差的关键所在，因为这些数据并不符合泊松分布的假设，他们和之前的数据是有关联的！</strong>当他筛选了数据，仅仅选取第一次打入的电话作为数据的时候，数据完全符合泊松分布。<strong>从别人的经验我们要看到自己未意识到的危机，也许现在上课的数据都为我们整理好了，但是将来我们需要自己构建模型的时候需要注意检验数据是否符合假设。</strong></p>
<h3 id="Dummy-Variable"><a href="#Dummy-Variable" class="headerlink" title="Dummy Variable"></a>Dummy Variable</h3><p><strong>永远不要把所有的Dummy Variable都放入你的线性模型，总要省去一个作为常数$b_{0}$的默认项。</strong>对于为什么总是要省去一个哑变量，我之前在学习R数据挖掘的时候一直不是很明白，但是这里老师打了一个形象的比方。就是把一个放入模型中的哑变量看做一盏灯的开关，这个房间里不能黑灯瞎火，总要有一盏灯亮着。当把所有的哑变量全部加入到模型中时：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression_DV-1.jpg" alt="Dummy Variable instance"><br>这下可能比较容易看出来，常数项$b<em>{0}$没有了对应的灯，那$b</em>{0} =  1$的时候代表的是房间的那盏灯亮呢？<strong>这样说比较通俗简单，用学术的话来说就是加入所有的哑变量后，最后一个哑变量会和常数项产生矛盾，模型会出现多重共线性的问题，因此我们总需要舍弃掉一个哑变量。</strong>正确的情况是这样的：<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression_DV-2.jpg" alt="right condition"></p>
<h3 id="选择变量"><a href="#选择变量" class="headerlink" title="选择变量"></a>选择变量</h3><p>要进行筛选变量的原因有两个：</p>
<ol>
<li>有的变量可能是相关性不强的变量，那么放入模型中的话会导致预测值也变得不那么准确(Trash in = Trash out)</li>
<li>太多变量会让模型变得复杂难以解释，筛选模型可以让模型变得简单易懂</li>
</ol>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression3.png" alt="Why We Need to Select Variables"><br>共有5种方法可以筛选要放入模型进行建模的变量：</p>
<ol>
<li>All in</li>
<li>Backward Elimination</li>
<li>Forward Elimination</li>
<li>Bidirectional  Elimination</li>
<li>Score Comparison</li>
</ol>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression4.png" alt="5 Ways to select variables"></p>
<h4 id="All-in"><a href="#All-in" class="headerlink" title="All in"></a>All in</h4><p>这是老师自创的名称，并非术语。顾名思义的，这种思路就是把所有的变量都放到模型中去。但是通常很少这样做。<strong>除非我们对实验的变量都非常了解，非常肯定他们对预测值都会有贡献，有影响，有关联，这个时候才会将所有的变量都放入模型中。</strong>通常，我们还是需要筛选一下变量再建模。</p>
<h4 id="Backward-Elimination"><a href="#Backward-Elimination" class="headerlink" title="Backward Elimination"></a>Backward Elimination</h4><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression5.png" alt="Backward Elimination"></p>
<p><strong>向后法</strong>，就是从所有变量中逐步的剔除最次的变量（相关性最差），一直到最终的满意情况。主要有5步：</p>
<ol>
<li>选择一个自己中意的重要性水平<code>SL</code></li>
<li>利用所有的变量构建模型</li>
<li>查看变量的<code>p值</code>，选择拥有最大<code>p值</code>的变量</li>
<li>如果<code>p值</code>大于<code>SL</code>，那就删去他，否则就结束筛选</li>
<li>再利用剩余的变量建模，再查看<code>p值</code>…</li>
</ol>
<h4 id="Forward-Elimination"><a href="#Forward-Elimination" class="headerlink" title="Forward Elimination"></a>Forward Elimination</h4><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression6.png" alt="Forward Elimination"></p>
<p><strong>向前法</strong>，和向后法相反，是从所有变量中选择最好的变量放入模型中，一直到没有好的变量为止：</p>
<ol>
<li>选择一个自己中意的重要性水平<code>SL</code></li>
<li>利用所有的变量构建模型</li>
<li>查看变量的<code>p值</code>，选择拥有最小<code>p值</code>的变量</li>
<li>如果<code>p值</code>小于<code>SL</code>，那就放入模型，否则就结束筛选</li>
<li>再利用剩余的变量建模，再查看<code>p值</code>…</li>
</ol>
<h4 id="Bidirectional-Elimination"><a href="#Bidirectional-Elimination" class="headerlink" title="Bidirectional  Elimination"></a>Bidirectional  Elimination</h4><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression7.png" alt="Bidirectional  Elimination"></p>
<p><strong>向前向后法</strong>（这是我之前学R语言数据挖掘的时候那个老师用的叫法，其实我觉得听!挺土的。。。）就是结合了向前法和向后法，先用向前法筛选一遍，再用向后法筛选一遍，直到最后无论怎么筛选模型变量都不再发生变化，就算是结束了。</p>
<h4 id="Score-Comparison"><a href="#Score-Comparison" class="headerlink" title="Score Comparison"></a>Score Comparison</h4><p><strong>整理出所有可能的变量搭配组合，并检验每种可能的表现如何。</strong>这种方法也不常用，要知道随着变量的数量增加，组合的数量是急速增加的，要用这种“穷举法”实在有些浪费时间。</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="筛选变量"><a href="#筛选变量" class="headerlink" title="筛选变量"></a>筛选变量</h4><p>这里用了<em>向后法</em>来筛选变量，需要用到<code>statsmodels.formula.api</code>。第二行创建常数列<code>Series(np.ones(50).astype(int))</code>是为了在筛选变量的时候让程序知道我们构建的模型还有一个常数项$b_{0}$。之后复制一个训练集数据，用作之后修改放入模型的变量，要知道元数据最好不要做修改。用<code>sm.OLS().fit()</code>method来建立模型，并用模型的<code>summary()</code>method查看各个变量的<code>p值</code>。下图是<code>summary()</code>的返回值。之后照向后法的步骤，去掉最次的变量。然后再开始构建，再筛选，直至结束。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Multiple_Linear_Regression8.png" alt="summary"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Building the optinal model using backward elimination</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> sm</span><br><span class="line">constant = Series(np.ones(<span class="number">50</span>).astype(int))</span><br><span class="line">X = pd.concat([constant, X], axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># round 1</span></span><br><span class="line">X_opt = X.copy()</span><br><span class="line">regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()</span><br><span class="line">regressor_OLS.summary()</span><br><span class="line"><span class="comment"># round 2</span></span><br><span class="line">X_opt = X_opt.drop(<span class="string">'State_California'</span>, axis=<span class="number">1</span>)</span><br><span class="line">regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()</span><br><span class="line">regressor_OLS.summary()</span><br><span class="line"><span class="comment"># round 3</span></span><br><span class="line">X_opt = X_opt.drop(<span class="string">'State_Florida'</span>, axis=<span class="number">1</span>)</span><br><span class="line">regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()</span><br><span class="line">regressor_OLS.summary()</span><br><span class="line"><span class="comment"># round 4</span></span><br><span class="line">X_opt = X_opt.drop(<span class="string">'Administration'</span>, axis=<span class="number">1</span>)</span><br><span class="line">regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()</span><br><span class="line">regressor_OLS.summary()</span><br></pre></td></tr></table></figure>
<h4 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h4><p>建立模型就相对简单了，和简单线性模型一样的，引入<code>LinearRegression</code>，建立一个模型，同样不需要设置任何的参数，然后<code>fit()</code>到训练集上，一个模型就建立完成了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fitting Multiple Linear Regression to the Training set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the test set results</span></span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/17/Simple-Linear-Regression/" itemprop="url">
                  Simple Linear Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-17T10:30:05+08:00" content="2017-07-17">
              2017-07-17
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageSimple_Linear_Regression.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part2-1"><a href="#Machine-Learning-A-Z-Part2-1" class="headerlink" title="Machine Learning A-Z Part2 - 1"></a>Machine Learning A-Z Part2 - 1</h1><h2 id="Simple-Linear-Regression"><a href="#Simple-Linear-Regression" class="headerlink" title="Simple Linear Regression"></a>Simple Linear Regression</h2><h3 id="数据概览"><a href="#数据概览" class="headerlink" title="数据概览"></a>数据概览</h3><p>这次的数据是有关入职时间和工资的<br><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Simple_Linear_Regression2.png" alt="Dataset Structure"></p>
<h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><h4 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h4><p>和之前一样，我们需要先导入数据集，将其分成特征值和目标值两个部分，然后再使用<code>train_test_split()</code>将数据分成测试集和训练集。</p>
<h4 id="Fitting-Simple-Linear-Regression-to-the-Training-set"><a href="#Fitting-Simple-Linear-Regression-to-the-Training-set" class="headerlink" title="Fitting Simple Linear Regression to the Training set"></a>Fitting Simple Linear Regression to the Training set</h4><p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Simple_Linear_Regression1.png" alt="Simple Linear Regression Model"><br>使用简单线性模型需要用到<code>sklearn.linear_model</code>模块中的<code>LinearRegression</code>类。首先要创建一个<code>LinearRegression()</code>对象，不需要填入任何参数，因为默认<code>LinearRegression()</code>对象就是简单线性模型。然后用<code>fit()</code> Method使用训练集数据训练模型，需要传入的参数分别为<strong>训练集的特征值和训练集的目标值</strong>。这样就算完成了模型的创建。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<h4 id="Predicting-the-test-set-results"><a href="#Predicting-the-test-set-results" class="headerlink" title="Predicting the test set results"></a>Predicting the test set results</h4><p><code>fit()</code> Method 是用来训练模型的，而想要利用模型进行预测就要用到 <code>predict()</code> Method。<strong>只需要传入需要预测的X值</strong>，模型就会返回预测出的y值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>为了能更清晰更明白的看懂我们建立的简单线性模型和查看预测的值是否准确，我们使用<code>matplotlib.pyplot</code>来绘制散点图并在其上加上简单线性模型的线。</p>
<p><code>plt.scatter()</code>是绘制散点图的函数，<code>plt.plot()</code>用来加上线性模型的线。其他函数是丰富图表细节的，可以为图表加上标题、X轴名称、Y轴名称。最后用<code>plt.show()</code>来画出图表。从画出来的图表可以看出，对于这个数据集，简单线性模型的预测效果还是不错的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualising the Training set results</span></span><br><span class="line">plt.scatter(X_train, y_train, color=<span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_train, regressor.predict(X_train), color=<span class="string">'blue'</span>)</span><br><span class="line">plt.title(<span class="string">'Salary vs Experience &#123;Training set&#125;'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Year or Experience'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Salary'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Simple_Linear_Regression3.png" alt="Train set plot"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Visualising the Test set results</span><br><span class="line">plt.scatter(X_test, y_test, color=&apos;red&apos;)</span><br><span class="line">plt.plot(X_train, regressor.predict(X_train), color=&apos;blue&apos;)</span><br><span class="line">plt.title(&apos;Salary vs Experience &#123;Test set&#125;&apos;)</span><br><span class="line">plt.xlabel(&apos;Year or Experience&apos;)</span><br><span class="line">plt.ylabel(&apos;Salary&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com//Regression/Simple_Linear_Regression4.png" alt="test set plot"></p>
<h3 id="R"><a href="#R" class="headerlink" title="R"></a>R</h3><p>I’ll learn R part later…</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/16/Machine-Learning-Preprocessing/" itemprop="url">
                  Machine Learning - Preprocessing
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-16T22:11:17+08:00" content="2017-07-16">
              2017-07-16
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimageMachine_Learning.jpg" class="full-image"></p>
<h1 id="Machine-Learning-A-Z-Part1"><a href="#Machine-Learning-A-Z-Part1" class="headerlink" title="Machine Learning A-Z Part1"></a>Machine Learning A-Z Part1</h1><h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><h3 id="Importing-the-Libraries"><a href="#Importing-the-Libraries" class="headerlink" title="Importing the Libraries"></a>Importing the Libraries</h3><h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><p>在Python中需要每次执行<code>import</code>命令，在<em>spyder</em>中可以选中对应的行按下<code>Ctrl + Enter</code>来执行对应的代码。这里主要用到三个Libraries，和python for data analysis中一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><p>在R中不需要执行代码，只需在RStudio的Package中勾选特定的package就可以了。<br><img src="http://ojr2ayzzn.bkt.clouddn.com/R import package.png" alt="Alt text"></p>
<h3 id="Set-Working-Directory-and-Importing-the-Dataset"><a href="#Set-Working-Directory-and-Importing-the-Dataset" class="headerlink" title="Set Working Directory and Importing the Dataset"></a>Set Working Directory and Importing the Dataset</h3><h4 id="python-1"><a href="#python-1" class="headerlink" title="python"></a>python</h4><p>在spyder中可以在右上角的<em>File explorer</em>选项卡中选择对应的文件夹并设置为Working Directory。<br><img src="http://ojr2ayzzn.bkt.clouddn.com/py set work dir.png" alt="Alt text"></p>
<p>我们最常见的数据文件格式就是<em>csv</em>了，在python中最常用的csv导入函数就是pandas中的<code>read_csv()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>在数据导入的过程中，我们往往要把独立变量(Independence Variables)和非独立变量(Dependence Variables)即我们需要预测的值分开来。这时候需要做一个slice，要用到<code>iloc[]</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Indep_df = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">Dep_df = dataset.iloc[:, <span class="number">3</span>].values</span><br></pre></td></tr></table></figure>
<h4 id="R-1"><a href="#R-1" class="headerlink" title="R"></a>R</h4><p>在RStudio中，可以在<em>Files</em>中设置工作路径。<br><img src="http://ojr2ayzzn.bkt.clouddn.com/R set work dir.png" alt="Alt text"></p>
<p>在R中使用<code>read.csv()</code>可以导入<em>csv</em>文件。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = read.csv(<span class="string">'Data.csv'</span>)</span><br></pre></td></tr></table></figure></p>
<p>还有一个不同的是，在R中我们不需要对导入的数据进行切割处理，不用分出独立变量表和非独立变量表。</p>
<h3 id="Missing-Data"><a href="#Missing-Data" class="headerlink" title="Missing Data"></a>Missing Data</h3><h4 id="python-2"><a href="#python-2" class="headerlink" title="python"></a>python</h4><p>盲目的丢掉一行缺失数据是不合适的，通常在可行的情况下我们会选择填补缺失值，在Python中我们可以使用sklearn package 中的<code>Imputer</code>来填补缺失值。</p>
<blockquote>
<p>对于我们不熟悉的package或object，可以在<strong>导入之后</strong>，将光标移到object上按下<code>Ctrl + I</code>(inspect)来查看doc。</p>
</blockquote>
<p>填补缺失值的步骤：</p>
<ol>
<li>导入<code>Imputer</code></li>
<li>设置<code>Imputer</code>参数（指定对应的缺失值类型，填补的方法，沿着哪个轴进行计算填补）</li>
<li>将设置好的<code>Imputer</code>obj <code>fit</code>给需要处理的列</li>
<li>将需要处理的列进行数据替换(<code>transform</code>)</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(missing_values=<span class="string">'NaN'</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</span><br><span class="line">imputer = imputer.fit(Indep_df[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">Indep_df[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(Indep_df[:, <span class="number">1</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<p>我不知道为什么老师没有考虑使用pandas中的<code>fillna()</code>函数，事实上我觉得这个函数远比<code>Imputer</code>使用来的方便，只需要一个函数就够了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Indep_df[:, <span class="number">1</span>:<span class="number">3</span>] = Indep_df[:, <span class="number">1</span>:<span class="number">3</span>].fillna(method=<span class="string">'mean'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="R-2"><a href="#R-2" class="headerlink" title="R"></a>R</h4><p>在R中处理缺失值需要自己利用<code>ifelse()</code>来构造一个函数，判断单元格是否是NA值，并指定返回一个值。</p>
<p>构造的函数结构和思路：</p>
<ul>
<li><code>ifelse()</code>：<ul>
<li><code>is.na()</code>：判断一个值是否是缺失值</li>
<li><em>If TRUE</em> <code>ave()</code>：计算一个平均值<ul>
<li><code>FUN</code> 指定计算的函数<ul>
<li><code>function(x)</code>自己指定<code>mean()</code>为函数，并设定<code>na.rm=TRUE</code>来计算**除去NA值以后的平均值。</li>
</ul>
</li>
</ul>
</li>
<li><em>if FALSE</em> <code>dataset$Age</code>：返回原值</li>
</ul>
</li>
</ul>
<p>以下是<code>ave()</code>的doc<br><img src="http://ojr2ayzzn.bkt.clouddn.com/ave doc.png" alt="Alt text"></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataset$Age = ifelse(is.na(dataset$Age),</span><br><span class="line">                     ave(dataset$Age, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                     dataset$Age)</span><br><span class="line">dataset$Salary = ifelse(is.na(dataset$Salary),</span><br><span class="line">                        ave(dataset$Salary, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                        dataset$Age)</span><br></pre></td></tr></table></figure>
<p>可以看到，同样处理两列数据的缺失值，R的代码要多很多，而且因为在R语言中最好不要使用循环（内存占用的问题？），代码的循环使用率很低。</p>
<h3 id="Categorical-Data"><a href="#Categorical-Data" class="headerlink" title="Categorical Data"></a>Categorical Data</h3><h4 id="python-3"><a href="#python-3" class="headerlink" title="python"></a>python</h4><p>在课程中老师使用了<code>sklearn</code>package来对分类变量进行处理，最终<strong>处理成为哑变量</strong>。</p>
<p>老师的步骤：</p>
<ol>
<li>import <code>LabelEncoder</code>和<code>OneHotEncoder</code></li>
<li>利用<code>LabelEncoder</code>将分类变量转换为数字</li>
</ol>
<ul>
<li>创建一个<code>LabelEncoder</code> obj</li>
<li>利用<code>fit_transform()</code>方法将其应用到要处理的列上</li>
</ul>
<ol>
<li>利用<code>OneHotEncoder</code>将已转换为数字的分类变量转变为哑变量</li>
</ol>
<ul>
<li>创建一个<code>OneHotEncoder</code> obj</li>
<li>利用<code>fit_transform()</code>方法将其应用到已转化为分类数字型的列上（<strong>只有在转化为数字型分类变量后才可以用 OneHotEncoder 进行处理！</strong>）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># change categorical string data into categorical num data</span></span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># change categorical num data into dummy variables</span></span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features=[<span class="number">0</span>])</span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br></pre></td></tr></table></figure>
<p>我对<code>sklearn</code>包还不熟悉，对<code>fit_transform</code>方法也不熟悉，下面是<code>fit_transform</code>方法的文档：<br><img src="http://ojr2ayzzn.bkt.clouddn.com/fit_trans doc.png" alt="Alt text"></p>
<p>事实上<code>pandas</code>库中的<code>get_dummies()</code>函数能更方便的将一列分类变量转化为哑变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dummies = pd.get_dummies(Indep_df.iloc[<span class="number">0</span>])</span><br><span class="line">dataset = dataset.join(dummies)</span><br></pre></td></tr></table></figure></p>
<h4 id="R-3"><a href="#R-3" class="headerlink" title="R"></a>R</h4><p>R中的分类变量无需做成哑变量（我也不知道为什么，老师在课程中并没有将R中的分类变量转换为哑变量，而仅仅是转换成了数字变量。）</p>
<p>R中只要使用<code>factor()</code>函数就可以了，有三个变量：</p>
<ol>
<li><strong>X:</strong> 传入需要进行转换的column</li>
<li><strong>levels:</strong> 传入需要转变的变量组成的向量<code>c()</code></li>
<li><strong>labels:</strong>  传入对应的转换成的数字组成的向量<code>c()</code></li>
</ol>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset$Country &lt;- factor(dataset$Country,</span><br><span class="line">                          levels = c(<span class="string">'France'</span>, <span class="string">'Spain'</span>, <span class="string">'Germany'</span>),</span><br><span class="line">                          labels = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>下面是<code>factor()</code>的doc<br><img src="http://ojr2ayzzn.bkt.clouddn.com/factor%20doc1.png" alt="enter image description here"><br><img src="http://ojr2ayzzn.bkt.clouddn.com/factor%20doc2.png" alt="enter image description here"></p>
<h3 id="Splitting-the-Dataset-into-the-Training-set-and-Test-set"><a href="#Splitting-the-Dataset-into-the-Training-set-and-Test-set" class="headerlink" title="Splitting the Dataset into the Training set and Test set"></a>Splitting the Dataset into the Training set and Test set</h3><h4 id="python-4"><a href="#python-4" class="headerlink" title="python"></a>python</h4><p>在<code>sklearn.cross_validation</code>package中有一个专门用来分割训练集和测试集的函数<code>train_test_split</code>。</p>
<p>在函数中<strong>将独立变量和非独立变量表格(array)分别传入，再设定测试集的比例(test_size)，再设定随机模式(random_state)</strong>就可以了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>下面是<code>train_test_split</code>的doc：<br><img src="http://ojr2ayzzn.bkt.clouddn.com/train_test_split%20doc1.png" alt="enter image description here"><br><img src="http://ojr2ayzzn.bkt.clouddn.com/train_test_split%20doc.png" alt="enter image description here"></p>
<h4 id="R-4"><a href="#R-4" class="headerlink" title="R"></a>R</h4><p>在R中选取训练集和测试集的思路有些不同，我们并非先将<em>独立变量</em>和<em>非独立变量</em>区分开来，而是先设定一个<strong>随机种子</strong>，然后获得一个<strong>由bool值组成的向量<code>split</code></strong>，最后根据这个向量（也可以理解为决定将数据分配到测试集还是训练集的名单）利用<code>subset()</code>函数将原先的数据集切分成训练集和测试集。</p>
<p>注：<strong>这里要使用到名叫<code>CaTool</code>的R包</strong></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set.seed(<span class="number">123</span>)</span><br><span class="line">split = sample.split(dataset$Purchased, SplitRatio = <span class="number">0.8</span>)</span><br><span class="line">training_set = subset(dataset, split = <span class="literal">TRUE</span>)</span><br><span class="line">test_set = subset(dataset, split == <span class="literal">FALSE</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h3><h4 id="python-5"><a href="#python-5" class="headerlink" title="python"></a>python</h4><p>在python中仍然是<code>sklearn.preprocessing</code>package能帮助我们完成Feature Scaling的工作，其实就是对数据进行<em>学生标准化或者极差标准化</em>，以保证数据的变化维度是一样的，<strong>不会有的数据极差很大导致其他变量的作用因为度量衡的原因而被影响</strong>。</p>
<p><img src="http://ojr2ayzzn.bkt.clouddn.com/Feature%20Scaling.png" alt="enter image description here"></p>
<p>对于<code>dataframe</code>对象，要将<code>StanderScaler()</code>方法<code>fit_transform()</code>到其上。而对于<code>Series</code>或者<code>array</code>对象，需要使用<code>transform()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>对于<strong>分类变量究竟是否需要进行标准化</strong>这个问题，网上有很多人有不同的见解，有的人说需要，有的人说不需要。课程中导师也给出了自己的意见——<strong>视你需要的模型精确度而定</strong>，事实上将分类变量的值范围标准化到与其他变量一样也对模型有一定影响。</p>
<h4 id="R-5"><a href="#R-5" class="headerlink" title="R"></a>R</h4><p>在R中进行标准化只需要用到一个函数<code>scale()</code>就够了。但是需要先搞清楚的是——<strong>如果我们武断地把这个函数应用在<code>data.frame</code>的所有列上，那么可能会出错，因为我们之前处理的分类变量类型是<code>factor</code>类，只有数字型的数据才能进行标准化，所以我们要利用切片器取出我们需要进行处理的列来进行标准化。</strong></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set[, <span class="number">2</span>:<span class="number">3</span>] = scale(training_set[, <span class="number">2</span>:<span class="number">3</span>])</span><br><span class="line">test_set[, <span class="number">2</span>:<span class="number">3</span>] = scale(test_set[, <span class="number">2</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/11/初识初试Git/" itemprop="url">
                  初识初试Git
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-11T09:50:56+08:00" content="2017-07-11">
              2017-07-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/闻叨/" itemprop="url" rel="index">
                    <span itemprop="name">闻叨</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://7xvrvp.com1.z0.glb.clouddn.com/blog_headimage%E5%88%9D%E8%AF%86%E5%88%9D%E8%AF%95Git.jpg" class="full-image"></p>
<h1 id="初识初试Git"><a href="#初识初试Git" class="headerlink" title="初识初试Git"></a>初识初试Git</h1><p>很早就听过GiHub，也很早就安装了Git，但是为了使用hexo写博客，必须要安装的。近来学习了很多Python数据分析的知识，希望自己日后进行数据分析或是数据挖掘时可以良好的备份代码，做好版本控制，因此萌发学习Git的念头。这是我初次尝试Git的一点学习笔记。</p>
<h2 id="链接本地与远程仓库"><a href="#链接本地与远程仓库" class="headerlink" title="链接本地与远程仓库"></a>链接本地与远程仓库</h2><p>使用Git最重要的配置就是使用<strong>SSH</strong>来连接本地项目和远程仓库，这样以后才可以把代码提交到自己指定的账号的仓库里去。很多人不知道SSH是什么，包括我第一次使用SSH来配置hexo的时候也是一头雾水。</p>
<blockquote>
<p>SSH是一种网络协议，用于计算机之间的加密登陆，目前是每台Linux电脑的标准配置。</p>
</blockquote>
<p>总之SSH就是一种密码，你要设置好秘钥，GitHub仓库才“认”你这个主人，让你上传文件修改仓库的内容。</p>
<h3 id="1-生成SSH-key"><a href="#1-生成SSH-key" class="headerlink" title="1. 生成SSH key"></a>1. 生成SSH key</h3><p>在Linux或者Mac的terminal中执行，如果是Windows需要在Git Bash中执行以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></p>
<p>随后会在<em>~/.ssh</em>目录下生成两个文件，一个是<code>id_rsa</code>另外一个是<code>id_rsa.pub</code>，很明显了，带有<code>pub</code>后缀的那个就是公钥（要在GitHub上添加），而没有的那个就是秘钥（自己电脑使用的）。</p>
<h3 id="2-在GitHub中添加SSH-key"><a href="#2-在GitHub中添加SSH-key" class="headerlink" title="2. 在GitHub中添加SSH key"></a>2. 在GitHub中添加SSH key</h3><p>先查看公钥的文件信息，使用下列命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh</span><br><span class="line">cat id_rsa.pub</span><br></pre></td></tr></table></figure></p>
<p>在GitHub的设置界面，点击<em>SSH and GPG keys</em>，然后点击右上角的<em>New SSH key</em>就会进入到添加SSH key的界面。在<em>Key</em>这一栏中添上刚刚<code>id_rsa.pub</code>文件的内容。在<em>Title</em>一栏中添上自己觉得明确的标题（对，可以自己随便取名字……）。</p>
<h3 id="3-确认连接成功"><a href="#3-确认连接成功" class="headerlink" title="3. 确认连接成功"></a>3. 确认连接成功</h3><p>按照以上步骤设置好之后其实已经算是设置成功了，但是为了以防万一，我们还可以最后在确认一次，看看本地主机书否真正的连接到了GitHub的远程仓库，使用以下命名。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></p>
<p>如果出现下列信息就说明已经配置成功了。</p>
<blockquote>
<p>Hi <your name="">! You’ve successfully authenticated, but GitHub does not porvide shell access.</your></p>
</blockquote>
<h2 id="初始化Git环境"><a href="#初始化Git环境" class="headerlink" title="初始化Git环境"></a>初始化Git环境</h2><p>要使用Git前要设定它工作的环境，<strong>我更简单的把它理解为，把某个项目文件夹设置为和远程GitHub仓库（当然也可以是其他仓库）同步</strong>。这里主要有两种方法可以设置：</p>
<ol>
<li>从GitHub上<code>clone</code>下来<br>如果你在GitHub上有一个项目需要继续修改，更新，改进，那可以直接执行命令，将GitHub上的项目同步到本地，并直接设置这个文件夹为工作目录，可以执行git命令。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone &lt;Your clone URL&gt;</span><br></pre></td></tr></table></figure>
<p><em>注：上面的<your clone="" url="">应改成自己需要同步的项目的URL，可以在GitHub仓库界面的右下角找到。</your></em></p>
<ol>
<li>从本地<code>init</code>并设置<code>remote add</code><br>如果你在本地已经编辑了一些文件，想要把文件传到GitHub上，并且以前读这个文件夹从来没有同步过，那你就需要<strong>先初始化这个文件夹，然后再把它添加到你指定的远程仓库中。</strong></li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd your_project_path/</span><br><span class="line">git remote add origin &lt;Your git URL&gt;</span><br></pre></td></tr></table></figure>
<p><em>注：上面的<your git="" url="">就是你的项目的网页链接。</your></em></p>
<h2 id="Git中的常用指令"><a href="#Git中的常用指令" class="headerlink" title="Git中的常用指令"></a>Git中的常用指令</h2><h3 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h3><h4 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h4><p>这条指令用来查看项目的状态，会返回<strong>项目中有哪些尚未被添加到缓存区的（<code>add</code>）文件，有哪些尚未被提交到仓库的（<code>commit</code>）文件。</strong></p>
<h4 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h4><p>这条命令会把当前项目中修改了的文件加入到缓存区里，什么是缓存区呢？<strong>我的理解是把项目同步到远程操库的操作类比为在食堂打饭，你修改了文件就是在张望，并没有确定自己就要排在川菜那一队或者杭帮菜那一队。而你的add操作就是确认排队，也就是让文件先排着队，对文件说，别着急，你先排着，还没轮到你呢。</strong></p>
<h4 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h4><p>这条命令会进行一次提交，就是确认修改过的文件将会进入本地主机的仓库中，要知道<strong>进行同步操作时，只有本地仓库里的文件才会和远程仓库里的文件同步</strong>。如果要继续沿用上面的食堂的例子的话，<strong>那我把commit理解为终于队伍排到了尽头，阿姨抡起大勺把菜砸在你的盘子里说“走你！”</strong>。</p>
<p>由此我们看到提交代码需要分开两步走，先<code>add</code>，再<code>commit</code>。为什么要两步走呢？毕竟你在食堂插队不好吧？另外一下就打了川菜，说不定看到杭帮菜就后悔了呢？哈哈哈。也就是说，最好遵循这样的规范，而且这样也是为了<strong>防止误提交</strong>。</p>
<p>通常来说，我们会这样用<code>commit</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &apos;This is a message.&apos;</span><br></pre></td></tr></table></figure></p>
<p>即可以给我们的提交操作加上一条解释信息，解释这次的提交有什么改动，有什么目的等等。</p>
<h4 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h4><p>这条命令可以查看<code>commit</code>记录，在《Learn Git from zero》中有一条更详细的<code>log</code>命令。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --graph --pretty=format:&apos;%Cred%h%Creset-%C(yellow)%d%Creset%s%Cgreen(%cr)%C(bold blue),&lt;%an&gt;%Creset&apos; --abbrev-commit --data=relative</span><br></pre></td></tr></table></figure></p>
<p>这条命令可以更清晰的看到commit编号，message,commit时间等等信息。</p>
<h4 id="git-tag"><a href="#git-tag" class="headerlink" title="git tag"></a>git tag</h4><p>在使用APP的时候，更新会说明自己出到<em>7.8.12</em>版本了。我们在开发的同时也会用到版本这个概念，一步步的将项目推向完善，修复一个个issue、bug。另外如果某一个新版本推出后有bug，还可以回滚以前的版本进行检查。添加版本号可以使用下面的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git tag v1.0      # 添加版本号v1.0</span><br><span class="line">git tag           # 查看tag历史</span><br><span class="line">git checkout v1.0 # 切换回1.0版本的项目代码</span><br></pre></td></tr></table></figure></p>
<h3 id="分支的理解和应用"><a href="#分支的理解和应用" class="headerlink" title="分支的理解和应用"></a>分支的理解和应用</h3><p>分支这个概念可能很多人都不熟悉，因为我们平常在本地进行coding的时候都是一个文件夹，自己逐步逐步的完善整个项目。但是因为Git是用来连接远程仓库的，是存在多人团队合作的，每个人有自己在团队中的分工，有的负责功能A，有的负责功能B，这个时候分支这个概念就起了很大的作用了，因为<strong>每个人可以在不同的分支把各自的功能代码完善，然后确认无误后再把不同的功能汇总起来，完成一个庞大的项目。</strong></p>
<h4 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h4><p>这个命令可以用来查看本地当前项目当中的分支列表，也可以<strong>在后面加上新分支的名字，用来新建一个分支</strong>；也可以<strong>在后面加上<code>-r</code>，即<code>remote</code>的意思，用来检查远程仓库的分支列表</strong>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git branch            # 查看本地分支列表</span><br><span class="line">git branch new_branch # 新建名为new_branch的分支</span><br><span class="line">git branch -r         # 查看远程分支列表</span><br></pre></td></tr></table></figure></p>
<h4 id="git-checkout"><a href="#git-checkout" class="headerlink" title="git checkout"></a>git checkout</h4><p>这个命令可以说是很多才多艺了：</p>
<ol>
<li>最常用的功能就是用来选择并跳转到一个分支</li>
<li>还可以在后面加上<code>-b</code>来直接新建并切换到新建的分支</li>
<li>当然也可以像前面一样用来回滚到以前的版本</li>
<li>也可以用来撤销一些还未进行<code>add</code>操作的代码。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git checkout a    # 转换到分支a</span><br><span class="line">git checkout -b a # 新建并转换到分支a</span><br><span class="line">git checkout v1.0 # 转换到1.0版本的代码</span><br><span class="line">git checkout a.md # 撤销还未add的a.md文档里的代码</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h4><p>当分支的代码已经完善并确认了之后，就可以将分支的代码合并回主分支（master）啦！这时候就用到了<code>merge</code>操作。这里要分两步走：</p>
<ol>
<li>切换到<code>master</code>分支</li>
<li>执行<code>git merge a</code>命令</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout master # 切换到a分支</span><br><span class="line">git merge a         # 将分支a上的代码合并到主分支上</span><br></pre></td></tr></table></figure>
<h4 id="git-branch-d"><a href="#git-branch-d" class="headerlink" title="git branch -d"></a>git branch -d</h4><p>这个命令后面加上分支的名字用来删除某个本地分支。有时候想删除会删不掉，因为分支内还有未合并的代码，Git会只能的提示你，如果想要强制删除某个分支，那么可以把小写的’d’改成大写的’D’。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch -d a # 删除a分支</span><br><span class="line">git branch -D a # 强制删除a分支</span><br></pre></td></tr></table></figure></p>
<h2 id="与远程分支同步"><a href="#与远程分支同步" class="headerlink" title="与远程分支同步"></a>与远程分支同步</h2><p>这里主要讲两个和远程仓库进行同步操作的指令，一个是<code>pull</code>，一个是<code>push</code>。</p>
<h3 id="push"><a href="#push" class="headerlink" title="push"></a>push</h3><p><code>push</code>是用来把本地的代码推到远程仓库里的操作，让本地的改动同步到远程仓库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure></p>
<h3 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h3><p><code>pull</code>是用来把远程仓库里的最新代码拉过来的操作，主要是当别人对代码进行了改动的时候，我们可以把新代码拉过来，保证两端是同步的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xvrvp.com1.z0.glb.clouddn.com/AlexanderLiu.jpg"
               alt="AlexanderLiu" />
          <p class="site-author-name" itemprop="name">AlexanderLiu</p>
          <p class="site-description motion-element" itemprop="description">不要效法这个世界，只要心意更新而变化，叫你们查验何为神的善良、纯全、可喜悦的旨意。（罗马书 12:2）</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">39</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AlexanderLiu</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  

  

</body>
</html>
